{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi-11nav/Text-Emotion-Detection/blob/main/Text_Emotion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zofTXg4alSny"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tiwW5EtC8MpQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hKbC0BeildcI"
      },
      "outputs": [],
      "source": [
        "# Importing data\n",
        "\n",
        "data = pd.read_csv(\"/content/Text-Emotion-Detection/tweet_emotions.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Yu8taALUlofD",
        "outputId": "d7aaebf4-c1a0-43e0-e2f6-ce73dd4438d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     tweet_id   sentiment                                            content\n",
              "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
              "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
              "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e9829f3-8c85-4507-944a-3cc232076bf9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1956967341</td>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1956967789</td>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1956968416</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e9829f3-8c85-4507-944a-3cc232076bf9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e9829f3-8c85-4507-944a-3cc232076bf9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e9829f3-8c85-4507-944a-3cc232076bf9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLCfmZ18pXYF"
      },
      "source": [
        "Funeral ceremony...gloomy friday..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TIUmyCIAmA-_"
      },
      "outputs": [],
      "source": [
        "# Let us drop the tweet id\n",
        "\n",
        "data.drop(\"tweet_id\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "uIDRz4D-mJXk",
        "outputId": "d865ea21-1ac9-44af-9c7c-5fdc7b8b6cd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sentiment                                            content\n",
              "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2     sadness                Funeral ceremony...gloomy friday...\n",
              "3  enthusiasm               wants to hang out with friends SOON!\n",
              "4     neutral  @dannycastillo We want to trade with someone w..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c778ec2b-3e4e-433d-aa35-127eb93235c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c778ec2b-3e4e-433d-aa35-127eb93235c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c778ec2b-3e4e-433d-aa35-127eb93235c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c778ec2b-3e4e-433d-aa35-127eb93235c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeEFLErwmZxK",
        "outputId": "7c33b45a-1714-44db-8437-12ba06ef4253"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment    False\n",
              "content      False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Let us check if the tweet has any missing values \n",
        "\n",
        "data.isna().any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syZBYwVdmubC"
      },
      "source": [
        "No missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLiURfjqmszA",
        "outputId": "eb7e8cdb-d312-4d4b-ce63-8961fce5857b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "boredom        179\n",
              "anger          110\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Let us check the number of categories in sentiment variable\n",
        "\n",
        "data['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRYV6lDBnsw7"
      },
      "source": [
        "Since the data is imbalanced, we'll be deadling with it "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEMWU1Y9GEbL"
      },
      "source": [
        "Data Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu2uF4piNa6F"
      },
      "source": [
        "### Eliminating the last two categories of sentiment as they are least represented. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uGGCatHTGE8P"
      },
      "outputs": [],
      "source": [
        "# dropping the last two samples\n",
        "\n",
        "# Appending indexes to remove\n",
        "indexes_to_remove = []\n",
        "\n",
        "\n",
        "for index in data[data['sentiment']==\"boredom\"].index:\n",
        "  indexes_to_remove.append(index)\n",
        "\n",
        "for index in data[data['sentiment']==\"anger\"].index:\n",
        "  indexes_to_remove.append(index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAgIIK9IOnll",
        "outputId": "bac2cfab-c6d9-4ac6-f8d6-d0157b47e6eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(indexes_to_remove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GaacF126Ono5"
      },
      "outputs": [],
      "source": [
        "data.drop(indexes_to_remove, inplace=True, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPl5Fzn4GE-x",
        "outputId": "0f3b1752-f461-423c-ee94-d3a63fd582ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data[\"sentiment\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7hl9qozlNPEr"
      },
      "outputs": [],
      "source": [
        "labels = [label for label in data[\"sentiment\"].unique()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bOK_Yc3lGFBK"
      },
      "outputs": [],
      "source": [
        "balanced_df = pd.DataFrame()\n",
        "\n",
        "for label in labels: \n",
        "  balanced_df = pd.concat([data[data[\"sentiment\"]==label].sample(759),balanced_df], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkiL8HfSGFGF",
        "outputId": "d73c69ee-f29a-4784-abb6-fc7e35980790"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "relief        759\n",
              "happiness     759\n",
              "hate          759\n",
              "fun           759\n",
              "love          759\n",
              "surprise      759\n",
              "worry         759\n",
              "neutral       759\n",
              "enthusiasm    759\n",
              "sadness       759\n",
              "empty         759\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "balanced_df[\"sentiment\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l65X2l8lXPjT"
      },
      "source": [
        " Now we have a balanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KhDwpJKWGFJO"
      },
      "outputs": [],
      "source": [
        "# shuffling samples and resetting indexes\n",
        "\n",
        "balanced_df = balanced_df.sample(len(balanced_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OLRi0Mj0YwGy"
      },
      "outputs": [],
      "source": [
        "balanced_df.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "xfkwmfzPYwCW",
        "outputId": "c4734d75-7324-41b0-8070-c1a3147a0f70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index   sentiment                                            content\n",
              "0  20303  enthusiasm  @BearNoiz Played An.World, played Flashback, p...\n",
              "1  25107   happiness  Can't help to look at my Twitter page and droo...\n",
              "2  36663    surprise  @alyssa905 Ooh, there you are, haha. Thanks, p...\n",
              "3  20789   happiness  @joek949 I'm okay thanks. No job yet but I'll ...\n",
              "4  25761   happiness                             In Paris till friday!!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bc48f27-f07c-465a-b2e3-13c1d50af370\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20303</td>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>@BearNoiz Played An.World, played Flashback, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25107</td>\n",
              "      <td>happiness</td>\n",
              "      <td>Can't help to look at my Twitter page and droo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36663</td>\n",
              "      <td>surprise</td>\n",
              "      <td>@alyssa905 Ooh, there you are, haha. Thanks, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20789</td>\n",
              "      <td>happiness</td>\n",
              "      <td>@joek949 I'm okay thanks. No job yet but I'll ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25761</td>\n",
              "      <td>happiness</td>\n",
              "      <td>In Paris till friday!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bc48f27-f07c-465a-b2e3-13c1d50af370')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3bc48f27-f07c-465a-b2e3-13c1d50af370 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3bc48f27-f07c-465a-b2e3-13c1d50af370');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "balanced_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RdsGAuZaYs49"
      },
      "outputs": [],
      "source": [
        "balanced_df.drop(\"index\", inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zeAMfYLJaFRW"
      },
      "outputs": [],
      "source": [
        "# Changing the name of the data frame\n",
        "\n",
        "data = balanced_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "4ITV_GjAnT70",
        "outputId": "3a0082a3-6b0d-4e82-d969-b3b6dc002a65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@BearNoiz Played An.World, played Flashback, played Starcon 2, played Fallout, played every Psygnosis game out for the Amiga and the ST'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Let us look at the sentences\n",
        "\n",
        "data['content'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "LqKVBAqVoMhn",
        "outputId": "29f0be98-93f9-41e6-b94d-efbb695573bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Can't help to look at my Twitter page and drool all over my custom bg: http://twitter.com/galvao\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "data['content'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9VKL5TVpDiw"
      },
      "source": [
        "Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMD6rP6Hr_xt",
        "outputId": "0f81d158-21a9-4070-81dc-ad3c683fd3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Importing libraries\n",
        "\n",
        "import re \n",
        "\n",
        "import nltk \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hG_T2DWSo925"
      },
      "outputs": [],
      "source": [
        "def text_preprocess(dataset,list_name):\n",
        "  \n",
        "  for i in range(dataset.shape[0]):\n",
        "    list_name.append(re.sub('[^a-zA-Z]',' ',str(dataset.iloc[i,1])))\n",
        "\n",
        "  print(\"Number and other symbols eliminated from the text\")\n",
        "\n",
        "  # String spacing \n",
        "  for x in range(len(list_name)):\n",
        "    list_name[x] = \" \".join(y for y in str(list_name[x]).split()).lower()\n",
        "\n",
        "  print(\"Text reorganized and converted to small letter\")\n",
        "  \n",
        "  for index in range(len(list_name)):\n",
        "    temp_list= []\n",
        "    # Lemmatization\n",
        "    for word in list_name[index].split():\n",
        "      if word not in stopwords.words('english'):\n",
        "        temp_list.append(word)\n",
        "    list_name[index] = \" \".join(lemmatizer.lemmatize(words) for words in temp_list )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiOLAlRoo952",
        "outputId": "6a721a0e-1eb5-4d94-a56c-0adc847ca1b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number and other symbols eliminated from the text\n",
            "Text reorganized and converted to small letter\n"
          ]
        }
      ],
      "source": [
        "sentences = []\n",
        "\n",
        "text_preprocess(data,sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rFIZ0Mdz5f6s"
      },
      "outputs": [],
      "source": [
        "p_data = pd.concat([pd.DataFrame(np.array(sentences), columns=[\"Content\"]), data['sentiment']], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "940QFH6M-rOY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "TcbulVrDFjHF",
        "outputId": "6afb7847-7016-4529-868a-b03fc133a3cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Content   sentiment\n",
              "0  bearnoiz played world played flashback played ...  enthusiasm\n",
              "1  help look twitter page drool custom bg http tw...   happiness\n",
              "2                      alyssa ooh haha thanks posted    surprise\n",
              "3  joek okay thanks job yet keep going get one ac...   happiness\n",
              "4                                  paris till friday   happiness"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59db5236-840d-4b7b-83ea-7e382bf5d986\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bearnoiz played world played flashback played ...</td>\n",
              "      <td>enthusiasm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>help look twitter page drool custom bg http tw...</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>alyssa ooh haha thanks posted</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>joek okay thanks job yet keep going get one ac...</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>paris till friday</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59db5236-840d-4b7b-83ea-7e382bf5d986')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59db5236-840d-4b7b-83ea-7e382bf5d986 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59db5236-840d-4b7b-83ea-7e382bf5d986');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "p_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_6z1WOXKbW5"
      },
      "source": [
        "Text preprocessing done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3E4xpOEmdNf"
      },
      "source": [
        "Reference : https://phdstatsphys.wordpress.com/2018/12/27/word2vec-how-to-train-and-update-it/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s6ApnHXN9Iu"
      },
      "source": [
        "We have vectors stored in **vectors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TExG04nXgaL5"
      },
      "source": [
        "## One hot encoding - padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zNE8xGUDaK6f"
      },
      "outputs": [],
      "source": [
        "unique_words = set()\n",
        "\n",
        "for sent in sentences:\n",
        "  for word in sent.split():\n",
        "    unique_words.add(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ymMTgmajaK8-"
      },
      "outputs": [],
      "source": [
        "unique_words = list(unique_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "k8JMp7BCaLBS"
      },
      "outputs": [],
      "source": [
        "# The length of unique words will be vocabulary size\n",
        "\n",
        "vocabulary_size = len(unique_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "KCci2g1ahQZo"
      },
      "outputs": [],
      "source": [
        "# Importing libraries for one hot encoding \n",
        "\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "d-ZbMXDgilYM"
      },
      "outputs": [],
      "source": [
        "sent_tokens = []\n",
        "\n",
        "for sent in sentences:\n",
        "  temp_list = []\n",
        "  for word in sent.split():\n",
        "    temp_list.append(word)\n",
        "  \n",
        "  sent_tokens.append(temp_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ghK351Sxudx",
        "outputId": "b469088a-df5d-4322-fc0e-ecbbd3f10e66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bearnoiz',\n",
              " 'played',\n",
              " 'world',\n",
              " 'played',\n",
              " 'flashback',\n",
              " 'played',\n",
              " 'starcon',\n",
              " 'played',\n",
              " 'fallout',\n",
              " 'played',\n",
              " 'every',\n",
              " 'psygnosis',\n",
              " 'game',\n",
              " 'amiga',\n",
              " 'st']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "[word for word in sent_tokens[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "opihn7XNh_BP"
      },
      "outputs": [],
      "source": [
        "sentences = [str(sent) for sent in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "OaBcbNT5h_Dx"
      },
      "outputs": [],
      "source": [
        "one_hot_vectors = []\n",
        "\n",
        "for sent in sent_tokens:\n",
        "  one_hot_vec = []\n",
        "  for words in sent:\n",
        "    one_hot_vec.append(one_hot(words,vocabulary_size)[0])\n",
        "  \n",
        "  one_hot_vectors.append(one_hot_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_Kx5O-2Uh_Gn"
      },
      "outputs": [],
      "source": [
        "# Importing libraries necessary for padding sequence\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "EbhA4JQDh_JB"
      },
      "outputs": [],
      "source": [
        "# Finding the sentence length \n",
        "\n",
        "max_len = 0\n",
        "\n",
        "for sent in sent_tokens:\n",
        "  if len(sent)>max_len:\n",
        "    max_len = len(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "tLiTI6Cvh_LT"
      },
      "outputs": [],
      "source": [
        "# Padding sequences \n",
        "\n",
        "embedded_docs = pad_sequences(one_hot_vectors,maxlen=max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZGWYzWcy4IVM"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries for embedded_docs \n",
        "\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "0yNkYt2Hh_OO"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size,100,input_length=max_len))\n",
        "model.compile('adam','mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_9dKRfb-h_SM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9303e12f-d048-4432-e290-119496fcb984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "261/261 [==============================] - 1s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "X = model.predict(embedded_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5YE2jlRQh_WT"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqsbsTw1h_aZ",
        "outputId": "4c034e22-e4b1-401b-93e1-7d579638b8d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "SaAIvPSb7A04"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "C4NPRR3S7A5D"
      },
      "outputs": [],
      "source": [
        "train_X,test_X, train_y, test_y = train_test_split(X,y,test_size=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7pVP7vl7A9G",
        "outputId": "8a14d33c-b57e-47d4-99fa-61841e97bda9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7096, 27, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "train_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i0a5Ln17BBO",
        "outputId": "5d71326d-4071-4719-dada-4514c557e052"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1253, 27, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "test_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIh6DtHz7Stp",
        "outputId": "3b2ae56c-4531-4817-92db-c88ca85fa6f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7096,)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "train_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0mTQgC-7Sx0",
        "outputId": "c8c2289a-48bd-4dbb-bffd-9d6e607638a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1253,)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "test_y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dndtBo0EUtUN"
      },
      "source": [
        "Converting text to vectors \n",
        "\n",
        "Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz-Kj1N0Uwgr",
        "outputId": "48e0e05e-16be-4e5d-f011-11352ece7cbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "import gensim\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04FTcZBfFa6K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5bKDKJyWx50",
        "outputId": "63729c56-53b4-40b4-ea82-e10a35c5962c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8349  length of sentences\n"
          ]
        }
      ],
      "source": [
        "# Words list\n",
        "\n",
        "words_list = []\n",
        "\n",
        "# looping through to append words\n",
        "for index in range(len(sentences)):\n",
        "  words_list.append(nltk.word_tokenize(sentences[index]))\n",
        "\n",
        "print(len(words_list),\" length of sentences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5cz9ytD_0x7",
        "outputId": "dbefb82a-13b5-400c-d6ad-922b002b3a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of empty lists are:  2\n"
          ]
        }
      ],
      "source": [
        "empty_lists = []\n",
        "\n",
        "for i,wl in enumerate(words_list):\n",
        "  if not wl:\n",
        "    empty_lists.append(i)\n",
        "\n",
        "print(\"The number of empty lists are: \", len(empty_lists))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83iHg3J0Agv-"
      },
      "source": [
        "Since there are 21 empty lists. We will combine them with the labels and drop the 21 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJUqQDY6AUY1",
        "outputId": "419bf799-66f8-400c-db83-ed16e814497b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "# Let us combine the dataset and get rid of any null values that may have occured after preprocessing\n",
        "\n",
        "preprocessed_data = pd.concat([pd.DataFrame(np.array(words_list)),pd.DataFrame(data['sentiment'])], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f6mabsOAz2D",
        "outputId": "0718abd3-3493-4934-ec93-92e521e6a92b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0            False\n",
              "sentiment    False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking for null values \n",
        "\n",
        "preprocessed_data.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHC82BgeAz5f",
        "outputId": "7bd5c715-96d0-4a3b-9346-0449ee43af98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "# We have empty lists that we have to get rid of and we have the indexes of those lists store in empty_lists list\n",
        "\n",
        "# Verifying elemnts from the list\n",
        "\n",
        "for indexes in empty_lists:\n",
        "  print(preprocessed_data.iloc[indexes,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY8pOwQhC0SH"
      },
      "source": [
        "There we go, our empty lists. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IarhUKTC5Q1"
      },
      "outputs": [],
      "source": [
        "preprocessed_data.drop(empty_lists, axis=0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Re36EArC5Wv"
      },
      "outputs": [],
      "source": [
        "word_lists = [lists for lists in preprocessed_data.iloc[:,0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1zdnQ9KUwkB"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.Word2Vec(words_list, window=5, min_count = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifTQTZJnUwmX",
        "outputId": "5908d1a9-5d48-4dd1-b62a-a9aa577e3c9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/8347 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "100%|| 8347/8347 [00:01<00:00, 4737.44it/s]\n"
          ]
        }
      ],
      "source": [
        "# Empty list \n",
        "X = []\n",
        "\n",
        "# Looping though words\n",
        "for words in tqdm(word_lists):\n",
        "  X.append(np.mean([model.wv[word] for word in words if word in model.wv.index2word], axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k7AnxBbQuuD",
        "outputId": "9421a7f3-f11c-4193-a99d-976e4d6da076"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "# Coverting them to arrays\n",
        "\n",
        "X = np.array(X)\n",
        "y = preprocessed_data['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "eH6OFX88PW-9"
      },
      "outputs": [],
      "source": [
        "y = p_data['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "DCShbT5-Eigt"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "corresponding_num = []\n",
        "\n",
        "for ind,lab in enumerate(y.unique()):\n",
        "  labels.append(lab)\n",
        "  corresponding_num.append(ind)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "f_HgyyO9I5AM"
      },
      "outputs": [],
      "source": [
        "encodings = [val for val in y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "-rLjCOWcJINa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "for i,value in enumerate(encodings):\n",
        "  for ind,unique in enumerate(labels):\n",
        "    if value==unique:\n",
        "      encodings[i] = ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "99rsc72XJIU6"
      },
      "outputs": [],
      "source": [
        "\n",
        "encodings = np.array(encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "YbYXCJodJIfW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "y = encodings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8cABT2dFkCt"
      },
      "source": [
        "Checking types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5dYV-1CFjOq",
        "outputId": "14dc2fc0-79bc-4721-95df-3b484993e41a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "# Converting all the arrays to same data type\n",
        "\n",
        "X = np.array([val.astype(np.float64) for val in X])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhc25PhbM6k_"
      },
      "source": [
        "Checking for null values in the array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEArqpIDM5R-",
        "outputId": "7de70cbb-8d2d-49fa-8b9d-132a1a2e7580"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    75\n",
              "dtype: int64"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(X).isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amLM-wY8NA6i"
      },
      "source": [
        "Found 227 null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67qxnjvcM5XQ"
      },
      "outputs": [],
      "source": [
        "# Let us combine the dataset and get rid of any null values that may have occured after preprocessing\n",
        "\n",
        "vector_data = pd.concat([pd.DataFrame(X),pd.DataFrame(y)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "yG3k9XQPNHsp",
        "outputId": "65fb6a57-ee12-4e3b-cd55-486a400e3f7b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3f5bd467-9570-4c38-9191-ee418e308e19\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.5185931921005249, -0.2783828675746918, -0.1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.3185077905654907, -0.1711403876543045, -0.1...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.39131638407707214, -0.21000224351882935, -0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.24084103107452393, -0.13017770648002625, -0...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.23725177347660065, -0.12525340914726257, -0...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f5bd467-9570-4c38-9191-ee418e308e19')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f5bd467-9570-4c38-9191-ee418e308e19 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f5bd467-9570-4c38-9191-ee418e308e19');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   0  0\n",
              "0  [0.5185931921005249, -0.2783828675746918, -0.1...  0\n",
              "1  [0.3185077905654907, -0.1711403876543045, -0.1...  1\n",
              "2  [0.39131638407707214, -0.21000224351882935, -0...  2\n",
              "3  [0.24084103107452393, -0.13017770648002625, -0...  1\n",
              "4  [0.23725177347660065, -0.12525340914726257, -0...  3"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqjqVQLPNHvB",
        "outputId": "c685d4a0-95be-4e46-eb6f-01dcd426a85f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     True\n",
              "0    False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_data.isna().any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uibrYSgwNZqX"
      },
      "source": [
        "Dropping all the null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzaBHu7SNHy-"
      },
      "outputs": [],
      "source": [
        "vector_data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoPqfsDLNH1D",
        "outputId": "89147518-f3e6-4c0a-c6cc-f70d3a2a0474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8272, 2)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adcOf2r7Ipg9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTVYNjgtNH5A"
      },
      "outputs": [],
      "source": [
        "X = np.array([feat for feat in vector_data.iloc[:,0]])\n",
        "y = np.array([label for label in vector_data.iloc[:,1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJpmXLdErQ5O"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X,y, train_size = 0.93, random_state= 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFVzraZyx777"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaRfyukTL4Gc",
        "outputId": "2c234576-6de1-4c0d-ae91-f3d45b738e17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gnb = GaussianNB()\n",
        "\n",
        "gnb.fit(train_X, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qqIIkV5rRGT"
      },
      "outputs": [],
      "source": [
        "predictions = gnb.predict(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlVYC7SsOQ_L"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHrQlJJurRLM"
      },
      "outputs": [],
      "source": [
        "score = accuracy_score(test_y, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv2YvqIHs31U",
        "outputId": "e19131d8-ecff-4120-a36c-b2e03fec82ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "And the final score is ...... ..... ... 0.11896551724137931\n"
          ]
        }
      ],
      "source": [
        "print(\"And the final score is ...... ..... ...\", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO6JNpqds4EL",
        "outputId": "5d6725f0-402a-40b6-c857-e9c0f726df29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7692, 100)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw19XNuds4Ho",
        "outputId": "7997a17e-7824-48e6-a0a9-54a1f87432f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7692,)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URVaZQekacN8",
        "outputId": "ddba76c9-e2cc-45f5-cd0e-b959ca83f34a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 300)\n",
            "(7, 300)\n",
            "(3, 300)\n",
            "(15, 300)\n",
            "(5, 300)\n",
            "(8,)\n",
            "(8, 300)\n",
            "(7, 300)\n",
            "(3, 300)\n",
            "(15, 300)\n"
          ]
        }
      ],
      "source": [
        "for v in range(len(vectors[:10])):\n",
        "  print(vectors[v].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS7mqYbAacQq",
        "outputId": "84716a4e-77a3-435b-91f6-1899f188f855"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.13769531,  0.03540039,  0.59765625, ..., -0.22167969,\n",
              "        -0.20800781,  0.00340271],\n",
              "       [-0.21875   ,  0.08154297,  0.29492188, ..., -0.5078125 ,\n",
              "         0.02172852, -0.11669922],\n",
              "       [ 0.04785156, -0.26757812,  0.07324219, ..., -0.27148438,\n",
              "        -0.06542969,  0.328125  ],\n",
              "       [-0.04785156,  0.16699219,  0.078125  , ..., -0.29101562,\n",
              "         0.04467773,  0.16113281],\n",
              "       [ 0.08154297, -0.06396484,  0.02526855, ..., -0.14160156,\n",
              "        -0.05395508, -0.07666016]], dtype=float32)"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectors[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWwLHCjzzs4O"
      },
      "source": [
        "Converting to categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "PwTWvlVCzV4o"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "kBvpSoXWzV8-"
      },
      "outputs": [],
      "source": [
        "train_y = to_categorical(train_y,13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "UBStd_0dEIHH"
      },
      "outputs": [],
      "source": [
        "# Covertiing test_y to binary \n",
        "test_y = to_categorical(test_y,13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RnOqTwSb53z"
      },
      "source": [
        "## TERM FREQUENCY - INVERSE DOCUMENT FREQUENCY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq8Nf_TAb-EK"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mujCAxBnb-HM"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "a_HQeLUttL-9",
        "outputId": "6ec28d68-53c1-4bc5-c9c1-ed231f0cbf5b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-62a6909e-7ba0-47eb-909d-74bbe446759f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>supersense ooooo explanation thank god u would...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>last day senior bye bff</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>noiselesssound heard regina girl song le deux ...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>someone said wolverine feel like watching x me...</td>\n",
              "      <td>fun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shanselman still class loader even custom asse...</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62a6909e-7ba0-47eb-909d-74bbe446759f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62a6909e-7ba0-47eb-909d-74bbe446759f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62a6909e-7ba0-47eb-909d-74bbe446759f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             Content sentiment\n",
              "0  supersense ooooo explanation thank god u would...      love\n",
              "1                            last day senior bye bff   sadness\n",
              "2  noiselesssound heard regina girl song le deux ...   sadness\n",
              "3  someone said wolverine feel like watching x me...       fun\n",
              "4  shanselman still class loader even custom asse...     empty"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpMKgtXhta85"
      },
      "outputs": [],
      "source": [
        "X = p_data['Content']\n",
        "y= p_data[\"sentiment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkpvR-4tvVQO"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "corresponding_num = []\n",
        "\n",
        "encodings = [val for val in y]\n",
        "\n",
        "for ind,lab in enumerate(y.unique()):\n",
        "  labels.append(lab)\n",
        "  corresponding_num.append(ind)\n",
        "\n",
        "for i,value in enumerate(encodings):\n",
        "  for ind,unique in enumerate(labels):\n",
        "    if value==unique:\n",
        "      encodings[i] = ind\n",
        "\n",
        "encodings = np.array(encodings)\n",
        "\n",
        "y = encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFYVEpl8tT7p"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y , test_size=0.11, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTerr2FltIgI"
      },
      "outputs": [],
      "source": [
        "train_sent = [sent for sent in train_X]\n",
        "test_sent = [sent for sent in test_X]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS5jnMdYb-Jg"
      },
      "outputs": [],
      "source": [
        "train_X = vectorizer.fit_transform(train_sent)\n",
        "test_X = vectorizer.transform(test_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "cYojcjOIlMmb",
        "outputId": "fa773d7c-bee1-41ba-ac9c-ed1111fc964a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'supersense ooooo explanation thank god u would forever wondering love good night mare tho'"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0BYa0BSb-T4"
      },
      "outputs": [],
      "source": [
        "# Covertiing test_y to binary \n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "train_y = to_categorical(train_y,13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqwR1KIZu0qa"
      },
      "outputs": [],
      "source": [
        "test_y = to_categorical(test_y,13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqxLSuNnvhue",
        "outputId": "f6f0a82c-e8b5-4389-f6ea-c8564c393e52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7430, 13539)"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ_uu-D8Kdh8"
      },
      "source": [
        "## LSTM RNN MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB9_UQpFN-iD"
      },
      "source": [
        "Implementing Bi-directional Long short term Memory recurrent neural network "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "5XctiZrBJqNu"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries\n",
        "\n",
        "import tensorflow \n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers import Dense, Flatten, Input, LSTM, Bidirectional, Embedding, Dropout, CuDNNLSTM, GRU\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FX_cBlE8iHN",
        "outputId": "77c79dcf-d4d6-4160-a7a2-21c9be51b73d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "train_X.shape[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANsSvX-5HvnH"
      },
      "source": [
        "The fluctuations are normal within certain limits and depend on the fact that you use a heuristic method but in your case they are excessive. Despite all the performance takes a definite direction and therefore the system works. From the graphs you have posted, the problem depends on your data so it's a difficult training. If you have already tried to change the learning rate try to change training algorithm. You would agree to test your data: first compute the Bayes error rate using a KNN (use the trick regression in case you need), in this way you can check whether the input data contain all the information you need. Then try the LSTM without the validation or dropout to verify that it has the ability to achieve the result for you necessary. If the training algorithm is not suitable you should have the same problems even without the validation or dropout. Just at the end adjust the training and the validation size to get the best result in the test set. Statistical learning theory is not a topic that can be talked about at one time, we must proceed step by step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdaMQD09qzdD"
      },
      "source": [
        "source :https://stats.stackexchange.com/questions/345990/why-does-the-loss-accuracy-fluctuate-during-the-training-keras-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "YJvqoSDsy9-Q"
      },
      "outputs": [],
      "source": [
        "input = Input(shape=(27,100))\n",
        "lstm = CuDNNLSTM(3, return_sequences=True)(input)\n",
        "dropout = Dropout(0.2)(lstm)\n",
        "lstm2 = CuDNNLSTM(3, return_sequences=True)(dropout)\n",
        "dropout2 = Dropout(0.2)(lstm2)\n",
        "flatten= Flatten()(dropout2)\n",
        "prediction = Dense(13, activation=\"softmax\")(flatten)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "zS1hnHUt6ZNb"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "\n",
        "model = Model(inputs = input, outputs = prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSAZhDi-6e3b",
        "outputId": "ad780a55-1ed8-4dc6-ff2f-f71f0ea52d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 27, 100)]         0         \n",
            "                                                                 \n",
            " cu_dnnlstm (CuDNNLSTM)      (None, 27, 3)             1260      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 27, 3)             0         \n",
            "                                                                 \n",
            " cu_dnnlstm_1 (CuDNNLSTM)    (None, 27, 3)             96        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 27, 3)             0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 81)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 13)                1066      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,422\n",
            "Trainable params: 2,422\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "OoEALr471j2b"
      },
      "outputs": [],
      "source": [
        "# Setting the learning rate for the optimizer. \n",
        "\n",
        "adam_optimizer = keras.optimizers.Adam(learning_rate=1e-3, decay=1e-6)\n",
        "\n",
        "# Compiling the model\n",
        "\n",
        "model.compile(optimizer=adam_optimizer, loss=\"categorical_crossentropy\", metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaxBoFlHAySp"
      },
      "source": [
        "Keras callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "YAjvM2gpA6KC"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "RwBTC950A6rE"
      },
      "outputs": [],
      "source": [
        "patience = EarlyStopping(patience=200)\n",
        "\n",
        "save_best = ModelCheckpoint(\"lstm_model.h5\", save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_ZENR97Dzs7",
        "outputId": "2e132bfb-fe28-47b1-ed67-8f6cd905f09f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7096, 27, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "train_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwqYrrw2D2GA",
        "outputId": "8cdc5bed-cffd-4601-d4ed-714e6c391480"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7096, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "train_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l51f7vXD2JZ",
        "outputId": "263c9f8e-f28f-4a61-ee38-8718ffc77cae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1253, 27, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "test_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PogsbxKnD2M4",
        "outputId": "cc484144-2032-44db-9394-95aed48ceddc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1253, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "test_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwu7JZws1tJR",
        "outputId": "d770d6da-a3f4-4df3-8392-bffdd8ce9ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "222/222 [==============================] - 5s 8ms/step - loss: 2.4532 - accuracy: 0.0912 - val_loss: 2.4044 - val_accuracy: 0.1093\n",
            "Epoch 2/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.4146 - accuracy: 0.0889 - val_loss: 2.4054 - val_accuracy: 0.0998\n",
            "Epoch 3/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.4087 - accuracy: 0.0933 - val_loss: 2.3998 - val_accuracy: 0.0862\n",
            "Epoch 4/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.4040 - accuracy: 0.0908 - val_loss: 2.3970 - val_accuracy: 0.1014\n",
            "Epoch 5/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.4019 - accuracy: 0.0971 - val_loss: 2.3926 - val_accuracy: 0.1101\n",
            "Epoch 6/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.3975 - accuracy: 0.1022 - val_loss: 2.3875 - val_accuracy: 0.1133\n",
            "Epoch 7/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3931 - accuracy: 0.1064 - val_loss: 2.3838 - val_accuracy: 0.1189\n",
            "Epoch 8/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3867 - accuracy: 0.1110 - val_loss: 2.3783 - val_accuracy: 0.1309\n",
            "Epoch 9/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3813 - accuracy: 0.1191 - val_loss: 2.3735 - val_accuracy: 0.1261\n",
            "Epoch 10/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3733 - accuracy: 0.1219 - val_loss: 2.3675 - val_accuracy: 0.1205\n",
            "Epoch 11/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3630 - accuracy: 0.1357 - val_loss: 2.3614 - val_accuracy: 0.1309\n",
            "Epoch 12/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3518 - accuracy: 0.1330 - val_loss: 2.3557 - val_accuracy: 0.1468\n",
            "Epoch 13/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3471 - accuracy: 0.1350 - val_loss: 2.3544 - val_accuracy: 0.1413\n",
            "Epoch 14/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3409 - accuracy: 0.1381 - val_loss: 2.3504 - val_accuracy: 0.1413\n",
            "Epoch 15/1000\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 2.3408 - accuracy: 0.1415 - val_loss: 2.3531 - val_accuracy: 0.1405\n",
            "Epoch 16/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3371 - accuracy: 0.1432 - val_loss: 2.3478 - val_accuracy: 0.1500\n",
            "Epoch 17/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3321 - accuracy: 0.1470 - val_loss: 2.3475 - val_accuracy: 0.1437\n",
            "Epoch 18/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.3322 - accuracy: 0.1394 - val_loss: 2.3449 - val_accuracy: 0.1468\n",
            "Epoch 19/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3325 - accuracy: 0.1468 - val_loss: 2.3503 - val_accuracy: 0.1492\n",
            "Epoch 20/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3299 - accuracy: 0.1483 - val_loss: 2.3456 - val_accuracy: 0.1516\n",
            "Epoch 21/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3277 - accuracy: 0.1443 - val_loss: 2.3438 - val_accuracy: 0.1540\n",
            "Epoch 22/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3258 - accuracy: 0.1539 - val_loss: 2.3465 - val_accuracy: 0.1365\n",
            "Epoch 23/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.3229 - accuracy: 0.1539 - val_loss: 2.3430 - val_accuracy: 0.1516\n",
            "Epoch 24/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3235 - accuracy: 0.1512 - val_loss: 2.3426 - val_accuracy: 0.1572\n",
            "Epoch 25/1000\n",
            "222/222 [==============================] - 2s 10ms/step - loss: 2.3217 - accuracy: 0.1576 - val_loss: 2.3406 - val_accuracy: 0.1524\n",
            "Epoch 26/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.3206 - accuracy: 0.1559 - val_loss: 2.3388 - val_accuracy: 0.1516\n",
            "Epoch 27/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3201 - accuracy: 0.1605 - val_loss: 2.3491 - val_accuracy: 0.1476\n",
            "Epoch 28/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3198 - accuracy: 0.1557 - val_loss: 2.3411 - val_accuracy: 0.1532\n",
            "Epoch 29/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3190 - accuracy: 0.1560 - val_loss: 2.3416 - val_accuracy: 0.1620\n",
            "Epoch 30/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3155 - accuracy: 0.1622 - val_loss: 2.3447 - val_accuracy: 0.1468\n",
            "Epoch 31/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3131 - accuracy: 0.1607 - val_loss: 2.3364 - val_accuracy: 0.1620\n",
            "Epoch 32/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.3126 - accuracy: 0.1623 - val_loss: 2.3381 - val_accuracy: 0.1540\n",
            "Epoch 33/1000\n",
            "222/222 [==============================] - 1s 6ms/step - loss: 2.3101 - accuracy: 0.1608 - val_loss: 2.3427 - val_accuracy: 0.1460\n",
            "Epoch 34/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3117 - accuracy: 0.1650 - val_loss: 2.3388 - val_accuracy: 0.1516\n",
            "Epoch 35/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3092 - accuracy: 0.1592 - val_loss: 2.3368 - val_accuracy: 0.1564\n",
            "Epoch 36/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3116 - accuracy: 0.1646 - val_loss: 2.3393 - val_accuracy: 0.1532\n",
            "Epoch 37/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.3067 - accuracy: 0.1646 - val_loss: 2.3333 - val_accuracy: 0.1724\n",
            "Epoch 38/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3065 - accuracy: 0.1635 - val_loss: 2.3344 - val_accuracy: 0.1652\n",
            "Epoch 39/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.3071 - accuracy: 0.1646 - val_loss: 2.3337 - val_accuracy: 0.1564\n",
            "Epoch 40/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.3032 - accuracy: 0.1659 - val_loss: 2.3322 - val_accuracy: 0.1612\n",
            "Epoch 41/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.3007 - accuracy: 0.1670 - val_loss: 2.3316 - val_accuracy: 0.1564\n",
            "Epoch 42/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.3033 - accuracy: 0.1630 - val_loss: 2.3384 - val_accuracy: 0.1532\n",
            "Epoch 43/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.3029 - accuracy: 0.1709 - val_loss: 2.3335 - val_accuracy: 0.1636\n",
            "Epoch 44/1000\n",
            "222/222 [==============================] - 2s 11ms/step - loss: 2.2967 - accuracy: 0.1666 - val_loss: 2.3307 - val_accuracy: 0.1612\n",
            "Epoch 45/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2953 - accuracy: 0.1690 - val_loss: 2.3260 - val_accuracy: 0.1668\n",
            "Epoch 46/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2951 - accuracy: 0.1712 - val_loss: 2.3283 - val_accuracy: 0.1588\n",
            "Epoch 47/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2925 - accuracy: 0.1697 - val_loss: 2.3258 - val_accuracy: 0.1580\n",
            "Epoch 48/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2925 - accuracy: 0.1728 - val_loss: 2.3236 - val_accuracy: 0.1716\n",
            "Epoch 49/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2926 - accuracy: 0.1721 - val_loss: 2.3319 - val_accuracy: 0.1580\n",
            "Epoch 50/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2918 - accuracy: 0.1735 - val_loss: 2.3259 - val_accuracy: 0.1588\n",
            "Epoch 51/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2892 - accuracy: 0.1755 - val_loss: 2.3190 - val_accuracy: 0.1580\n",
            "Epoch 52/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2893 - accuracy: 0.1739 - val_loss: 2.3172 - val_accuracy: 0.1572\n",
            "Epoch 53/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2848 - accuracy: 0.1733 - val_loss: 2.3345 - val_accuracy: 0.1556\n",
            "Epoch 54/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2861 - accuracy: 0.1701 - val_loss: 2.3181 - val_accuracy: 0.1572\n",
            "Epoch 55/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2804 - accuracy: 0.1790 - val_loss: 2.3154 - val_accuracy: 0.1636\n",
            "Epoch 56/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2788 - accuracy: 0.1736 - val_loss: 2.3161 - val_accuracy: 0.1668\n",
            "Epoch 57/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2821 - accuracy: 0.1756 - val_loss: 2.3137 - val_accuracy: 0.1700\n",
            "Epoch 58/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2804 - accuracy: 0.1736 - val_loss: 2.3111 - val_accuracy: 0.1564\n",
            "Epoch 59/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2734 - accuracy: 0.1798 - val_loss: 2.3141 - val_accuracy: 0.1676\n",
            "Epoch 60/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2741 - accuracy: 0.1778 - val_loss: 2.3105 - val_accuracy: 0.1636\n",
            "Epoch 61/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2765 - accuracy: 0.1786 - val_loss: 2.3072 - val_accuracy: 0.1644\n",
            "Epoch 62/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2750 - accuracy: 0.1787 - val_loss: 2.3075 - val_accuracy: 0.1668\n",
            "Epoch 63/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2703 - accuracy: 0.1838 - val_loss: 2.3074 - val_accuracy: 0.1724\n",
            "Epoch 64/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2693 - accuracy: 0.1795 - val_loss: 2.3113 - val_accuracy: 0.1628\n",
            "Epoch 65/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2715 - accuracy: 0.1790 - val_loss: 2.3069 - val_accuracy: 0.1716\n",
            "Epoch 66/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2657 - accuracy: 0.1814 - val_loss: 2.3162 - val_accuracy: 0.1644\n",
            "Epoch 67/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2676 - accuracy: 0.1864 - val_loss: 2.3039 - val_accuracy: 0.1764\n",
            "Epoch 68/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2649 - accuracy: 0.1819 - val_loss: 2.3088 - val_accuracy: 0.1572\n",
            "Epoch 69/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2657 - accuracy: 0.1821 - val_loss: 2.3144 - val_accuracy: 0.1676\n",
            "Epoch 70/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2651 - accuracy: 0.1867 - val_loss: 2.3099 - val_accuracy: 0.1692\n",
            "Epoch 71/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2630 - accuracy: 0.1857 - val_loss: 2.3164 - val_accuracy: 0.1660\n",
            "Epoch 72/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2636 - accuracy: 0.1838 - val_loss: 2.3033 - val_accuracy: 0.1700\n",
            "Epoch 73/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2623 - accuracy: 0.1895 - val_loss: 2.3063 - val_accuracy: 0.1604\n",
            "Epoch 74/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2634 - accuracy: 0.1864 - val_loss: 2.3065 - val_accuracy: 0.1772\n",
            "Epoch 75/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2610 - accuracy: 0.1893 - val_loss: 2.3022 - val_accuracy: 0.1668\n",
            "Epoch 76/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2600 - accuracy: 0.1876 - val_loss: 2.3197 - val_accuracy: 0.1620\n",
            "Epoch 77/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2605 - accuracy: 0.1808 - val_loss: 2.3052 - val_accuracy: 0.1708\n",
            "Epoch 78/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2561 - accuracy: 0.1824 - val_loss: 2.3074 - val_accuracy: 0.1724\n",
            "Epoch 79/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2583 - accuracy: 0.1848 - val_loss: 2.3118 - val_accuracy: 0.1724\n",
            "Epoch 80/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2573 - accuracy: 0.1870 - val_loss: 2.3083 - val_accuracy: 0.1652\n",
            "Epoch 81/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2519 - accuracy: 0.1856 - val_loss: 2.3081 - val_accuracy: 0.1636\n",
            "Epoch 82/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2533 - accuracy: 0.1846 - val_loss: 2.3048 - val_accuracy: 0.1684\n",
            "Epoch 83/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2546 - accuracy: 0.1912 - val_loss: 2.3057 - val_accuracy: 0.1572\n",
            "Epoch 84/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2525 - accuracy: 0.1945 - val_loss: 2.3070 - val_accuracy: 0.1660\n",
            "Epoch 85/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2531 - accuracy: 0.1917 - val_loss: 2.3038 - val_accuracy: 0.1700\n",
            "Epoch 86/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2535 - accuracy: 0.1871 - val_loss: 2.3126 - val_accuracy: 0.1708\n",
            "Epoch 87/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2532 - accuracy: 0.1883 - val_loss: 2.3075 - val_accuracy: 0.1652\n",
            "Epoch 88/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2513 - accuracy: 0.1938 - val_loss: 2.3076 - val_accuracy: 0.1628\n",
            "Epoch 89/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2488 - accuracy: 0.1845 - val_loss: 2.3046 - val_accuracy: 0.1620\n",
            "Epoch 90/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2495 - accuracy: 0.1926 - val_loss: 2.3070 - val_accuracy: 0.1700\n",
            "Epoch 91/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2479 - accuracy: 0.1900 - val_loss: 2.3047 - val_accuracy: 0.1620\n",
            "Epoch 92/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2476 - accuracy: 0.1898 - val_loss: 2.3067 - val_accuracy: 0.1596\n",
            "Epoch 93/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2492 - accuracy: 0.1859 - val_loss: 2.3042 - val_accuracy: 0.1684\n",
            "Epoch 94/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2438 - accuracy: 0.1939 - val_loss: 2.3140 - val_accuracy: 0.1604\n",
            "Epoch 95/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2473 - accuracy: 0.1914 - val_loss: 2.3058 - val_accuracy: 0.1572\n",
            "Epoch 96/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2464 - accuracy: 0.1950 - val_loss: 2.3218 - val_accuracy: 0.1532\n",
            "Epoch 97/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2427 - accuracy: 0.1897 - val_loss: 2.3149 - val_accuracy: 0.1636\n",
            "Epoch 98/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2453 - accuracy: 0.1859 - val_loss: 2.3107 - val_accuracy: 0.1660\n",
            "Epoch 99/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2415 - accuracy: 0.1959 - val_loss: 2.3111 - val_accuracy: 0.1588\n",
            "Epoch 100/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2443 - accuracy: 0.1901 - val_loss: 2.3101 - val_accuracy: 0.1596\n",
            "Epoch 101/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2436 - accuracy: 0.1919 - val_loss: 2.3068 - val_accuracy: 0.1660\n",
            "Epoch 102/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2412 - accuracy: 0.1936 - val_loss: 2.3080 - val_accuracy: 0.1612\n",
            "Epoch 103/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2474 - accuracy: 0.1881 - val_loss: 2.3113 - val_accuracy: 0.1652\n",
            "Epoch 104/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2418 - accuracy: 0.1949 - val_loss: 2.3137 - val_accuracy: 0.1596\n",
            "Epoch 105/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2404 - accuracy: 0.1915 - val_loss: 2.3067 - val_accuracy: 0.1548\n",
            "Epoch 106/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2406 - accuracy: 0.1912 - val_loss: 2.3194 - val_accuracy: 0.1628\n",
            "Epoch 107/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2397 - accuracy: 0.1984 - val_loss: 2.3065 - val_accuracy: 0.1612\n",
            "Epoch 108/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2368 - accuracy: 0.1936 - val_loss: 2.3173 - val_accuracy: 0.1612\n",
            "Epoch 109/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2415 - accuracy: 0.1946 - val_loss: 2.3076 - val_accuracy: 0.1620\n",
            "Epoch 110/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2395 - accuracy: 0.1922 - val_loss: 2.3133 - val_accuracy: 0.1596\n",
            "Epoch 111/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2409 - accuracy: 0.1949 - val_loss: 2.3068 - val_accuracy: 0.1612\n",
            "Epoch 112/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2366 - accuracy: 0.1957 - val_loss: 2.3058 - val_accuracy: 0.1668\n",
            "Epoch 113/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2387 - accuracy: 0.1932 - val_loss: 2.3093 - val_accuracy: 0.1572\n",
            "Epoch 114/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2356 - accuracy: 0.2007 - val_loss: 2.3139 - val_accuracy: 0.1644\n",
            "Epoch 115/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2344 - accuracy: 0.2001 - val_loss: 2.3113 - val_accuracy: 0.1660\n",
            "Epoch 116/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2350 - accuracy: 0.1987 - val_loss: 2.3075 - val_accuracy: 0.1612\n",
            "Epoch 117/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2345 - accuracy: 0.1956 - val_loss: 2.3141 - val_accuracy: 0.1652\n",
            "Epoch 118/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2350 - accuracy: 0.1966 - val_loss: 2.3158 - val_accuracy: 0.1612\n",
            "Epoch 119/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2337 - accuracy: 0.1984 - val_loss: 2.3186 - val_accuracy: 0.1612\n",
            "Epoch 120/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2345 - accuracy: 0.2035 - val_loss: 2.3146 - val_accuracy: 0.1676\n",
            "Epoch 121/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2295 - accuracy: 0.1973 - val_loss: 2.3104 - val_accuracy: 0.1604\n",
            "Epoch 122/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2342 - accuracy: 0.1974 - val_loss: 2.3235 - val_accuracy: 0.1660\n",
            "Epoch 123/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2378 - accuracy: 0.1926 - val_loss: 2.3112 - val_accuracy: 0.1692\n",
            "Epoch 124/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2315 - accuracy: 0.1988 - val_loss: 2.3067 - val_accuracy: 0.1692\n",
            "Epoch 125/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2324 - accuracy: 0.1990 - val_loss: 2.3089 - val_accuracy: 0.1684\n",
            "Epoch 126/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2291 - accuracy: 0.2011 - val_loss: 2.3141 - val_accuracy: 0.1684\n",
            "Epoch 127/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2315 - accuracy: 0.2010 - val_loss: 2.3118 - val_accuracy: 0.1620\n",
            "Epoch 128/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2318 - accuracy: 0.1956 - val_loss: 2.3165 - val_accuracy: 0.1652\n",
            "Epoch 129/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2280 - accuracy: 0.1980 - val_loss: 2.3192 - val_accuracy: 0.1596\n",
            "Epoch 130/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2301 - accuracy: 0.1969 - val_loss: 2.3148 - val_accuracy: 0.1604\n",
            "Epoch 131/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2271 - accuracy: 0.1977 - val_loss: 2.3129 - val_accuracy: 0.1636\n",
            "Epoch 132/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2307 - accuracy: 0.2019 - val_loss: 2.3087 - val_accuracy: 0.1628\n",
            "Epoch 133/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2280 - accuracy: 0.1993 - val_loss: 2.3131 - val_accuracy: 0.1692\n",
            "Epoch 134/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2264 - accuracy: 0.1986 - val_loss: 2.3181 - val_accuracy: 0.1588\n",
            "Epoch 135/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2299 - accuracy: 0.1973 - val_loss: 2.3169 - val_accuracy: 0.1652\n",
            "Epoch 136/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2279 - accuracy: 0.2014 - val_loss: 2.3160 - val_accuracy: 0.1652\n",
            "Epoch 137/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2263 - accuracy: 0.2034 - val_loss: 2.3106 - val_accuracy: 0.1652\n",
            "Epoch 138/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2270 - accuracy: 0.1977 - val_loss: 2.3183 - val_accuracy: 0.1620\n",
            "Epoch 139/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2273 - accuracy: 0.1983 - val_loss: 2.3182 - val_accuracy: 0.1668\n",
            "Epoch 140/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2246 - accuracy: 0.2029 - val_loss: 2.3114 - val_accuracy: 0.1684\n",
            "Epoch 141/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2235 - accuracy: 0.2073 - val_loss: 2.3190 - val_accuracy: 0.1668\n",
            "Epoch 142/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2273 - accuracy: 0.2026 - val_loss: 2.3115 - val_accuracy: 0.1684\n",
            "Epoch 143/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2234 - accuracy: 0.1994 - val_loss: 2.3149 - val_accuracy: 0.1668\n",
            "Epoch 144/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2236 - accuracy: 0.2011 - val_loss: 2.3143 - val_accuracy: 0.1692\n",
            "Epoch 145/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2213 - accuracy: 0.2029 - val_loss: 2.3186 - val_accuracy: 0.1620\n",
            "Epoch 146/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2193 - accuracy: 0.2069 - val_loss: 2.3206 - val_accuracy: 0.1628\n",
            "Epoch 147/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2225 - accuracy: 0.2046 - val_loss: 2.3253 - val_accuracy: 0.1636\n",
            "Epoch 148/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2200 - accuracy: 0.2034 - val_loss: 2.3232 - val_accuracy: 0.1676\n",
            "Epoch 149/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2191 - accuracy: 0.2070 - val_loss: 2.3182 - val_accuracy: 0.1636\n",
            "Epoch 150/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2204 - accuracy: 0.2042 - val_loss: 2.3229 - val_accuracy: 0.1540\n",
            "Epoch 151/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2203 - accuracy: 0.2028 - val_loss: 2.3284 - val_accuracy: 0.1612\n",
            "Epoch 152/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2224 - accuracy: 0.2046 - val_loss: 2.3215 - val_accuracy: 0.1660\n",
            "Epoch 153/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2194 - accuracy: 0.2010 - val_loss: 2.3253 - val_accuracy: 0.1564\n",
            "Epoch 154/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2202 - accuracy: 0.2010 - val_loss: 2.3180 - val_accuracy: 0.1708\n",
            "Epoch 155/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2168 - accuracy: 0.2081 - val_loss: 2.3227 - val_accuracy: 0.1596\n",
            "Epoch 156/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2186 - accuracy: 0.2067 - val_loss: 2.3204 - val_accuracy: 0.1708\n",
            "Epoch 157/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2182 - accuracy: 0.2070 - val_loss: 2.3215 - val_accuracy: 0.1692\n",
            "Epoch 158/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2185 - accuracy: 0.2057 - val_loss: 2.3163 - val_accuracy: 0.1668\n",
            "Epoch 159/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2159 - accuracy: 0.2056 - val_loss: 2.3243 - val_accuracy: 0.1628\n",
            "Epoch 160/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2180 - accuracy: 0.2056 - val_loss: 2.3266 - val_accuracy: 0.1676\n",
            "Epoch 161/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2166 - accuracy: 0.2063 - val_loss: 2.3246 - val_accuracy: 0.1668\n",
            "Epoch 162/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2120 - accuracy: 0.2041 - val_loss: 2.3173 - val_accuracy: 0.1724\n",
            "Epoch 163/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2145 - accuracy: 0.2063 - val_loss: 2.3211 - val_accuracy: 0.1604\n",
            "Epoch 164/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2173 - accuracy: 0.2015 - val_loss: 2.3220 - val_accuracy: 0.1612\n",
            "Epoch 165/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2147 - accuracy: 0.2066 - val_loss: 2.3200 - val_accuracy: 0.1612\n",
            "Epoch 166/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2158 - accuracy: 0.2035 - val_loss: 2.3191 - val_accuracy: 0.1540\n",
            "Epoch 167/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2135 - accuracy: 0.2050 - val_loss: 2.3153 - val_accuracy: 0.1644\n",
            "Epoch 168/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2156 - accuracy: 0.2035 - val_loss: 2.3225 - val_accuracy: 0.1516\n",
            "Epoch 169/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2123 - accuracy: 0.2050 - val_loss: 2.3149 - val_accuracy: 0.1644\n",
            "Epoch 170/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2144 - accuracy: 0.2062 - val_loss: 2.3270 - val_accuracy: 0.1508\n",
            "Epoch 171/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2127 - accuracy: 0.2062 - val_loss: 2.3155 - val_accuracy: 0.1716\n",
            "Epoch 172/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2158 - accuracy: 0.2034 - val_loss: 2.3154 - val_accuracy: 0.1700\n",
            "Epoch 173/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2117 - accuracy: 0.2039 - val_loss: 2.3218 - val_accuracy: 0.1612\n",
            "Epoch 174/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2130 - accuracy: 0.2072 - val_loss: 2.3240 - val_accuracy: 0.1644\n",
            "Epoch 175/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2074 - accuracy: 0.2065 - val_loss: 2.3354 - val_accuracy: 0.1668\n",
            "Epoch 176/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2110 - accuracy: 0.2029 - val_loss: 2.3274 - val_accuracy: 0.1620\n",
            "Epoch 177/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2094 - accuracy: 0.2081 - val_loss: 2.3330 - val_accuracy: 0.1660\n",
            "Epoch 178/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2091 - accuracy: 0.2091 - val_loss: 2.3257 - val_accuracy: 0.1652\n",
            "Epoch 179/1000\n",
            "222/222 [==============================] - 2s 8ms/step - loss: 2.2089 - accuracy: 0.2067 - val_loss: 2.3256 - val_accuracy: 0.1684\n",
            "Epoch 180/1000\n",
            "222/222 [==============================] - 2s 9ms/step - loss: 2.2138 - accuracy: 0.2032 - val_loss: 2.3191 - val_accuracy: 0.1636\n",
            "Epoch 181/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2091 - accuracy: 0.2060 - val_loss: 2.3303 - val_accuracy: 0.1604\n",
            "Epoch 182/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2084 - accuracy: 0.2056 - val_loss: 2.3281 - val_accuracy: 0.1524\n",
            "Epoch 183/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2089 - accuracy: 0.2026 - val_loss: 2.3257 - val_accuracy: 0.1620\n",
            "Epoch 184/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2047 - accuracy: 0.2080 - val_loss: 2.3303 - val_accuracy: 0.1692\n",
            "Epoch 185/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2055 - accuracy: 0.2097 - val_loss: 2.3333 - val_accuracy: 0.1636\n",
            "Epoch 186/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2108 - accuracy: 0.2145 - val_loss: 2.3372 - val_accuracy: 0.1716\n",
            "Epoch 187/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2063 - accuracy: 0.2097 - val_loss: 2.3292 - val_accuracy: 0.1692\n",
            "Epoch 188/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2048 - accuracy: 0.2120 - val_loss: 2.3368 - val_accuracy: 0.1692\n",
            "Epoch 189/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2052 - accuracy: 0.2117 - val_loss: 2.3339 - val_accuracy: 0.1580\n",
            "Epoch 190/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2039 - accuracy: 0.2057 - val_loss: 2.3378 - val_accuracy: 0.1588\n",
            "Epoch 191/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2073 - accuracy: 0.2086 - val_loss: 2.3290 - val_accuracy: 0.1636\n",
            "Epoch 192/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2070 - accuracy: 0.2057 - val_loss: 2.3290 - val_accuracy: 0.1588\n",
            "Epoch 193/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2069 - accuracy: 0.2145 - val_loss: 2.3232 - val_accuracy: 0.1684\n",
            "Epoch 194/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2038 - accuracy: 0.2089 - val_loss: 2.3241 - val_accuracy: 0.1668\n",
            "Epoch 195/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2057 - accuracy: 0.2080 - val_loss: 2.3265 - val_accuracy: 0.1668\n",
            "Epoch 196/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2032 - accuracy: 0.2105 - val_loss: 2.3246 - val_accuracy: 0.1708\n",
            "Epoch 197/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2032 - accuracy: 0.2098 - val_loss: 2.3210 - val_accuracy: 0.1684\n",
            "Epoch 198/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.2036 - accuracy: 0.2060 - val_loss: 2.3270 - val_accuracy: 0.1628\n",
            "Epoch 199/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2058 - accuracy: 0.2115 - val_loss: 2.3295 - val_accuracy: 0.1588\n",
            "Epoch 200/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2016 - accuracy: 0.2107 - val_loss: 2.3231 - val_accuracy: 0.1708\n",
            "Epoch 201/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1993 - accuracy: 0.2166 - val_loss: 2.3222 - val_accuracy: 0.1692\n",
            "Epoch 202/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2018 - accuracy: 0.2118 - val_loss: 2.3269 - val_accuracy: 0.1612\n",
            "Epoch 203/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2055 - accuracy: 0.2074 - val_loss: 2.3423 - val_accuracy: 0.1572\n",
            "Epoch 204/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2011 - accuracy: 0.2118 - val_loss: 2.3261 - val_accuracy: 0.1628\n",
            "Epoch 205/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1991 - accuracy: 0.2108 - val_loss: 2.3406 - val_accuracy: 0.1532\n",
            "Epoch 206/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2024 - accuracy: 0.2111 - val_loss: 2.3373 - val_accuracy: 0.1564\n",
            "Epoch 207/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2018 - accuracy: 0.2117 - val_loss: 2.3387 - val_accuracy: 0.1772\n",
            "Epoch 208/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2007 - accuracy: 0.2086 - val_loss: 2.3327 - val_accuracy: 0.1724\n",
            "Epoch 209/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2033 - accuracy: 0.2089 - val_loss: 2.3439 - val_accuracy: 0.1572\n",
            "Epoch 210/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2044 - accuracy: 0.2117 - val_loss: 2.3372 - val_accuracy: 0.1580\n",
            "Epoch 211/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2016 - accuracy: 0.2098 - val_loss: 2.3285 - val_accuracy: 0.1652\n",
            "Epoch 212/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.2021 - accuracy: 0.2101 - val_loss: 2.3335 - val_accuracy: 0.1620\n",
            "Epoch 213/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1981 - accuracy: 0.2089 - val_loss: 2.3261 - val_accuracy: 0.1628\n",
            "Epoch 214/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1970 - accuracy: 0.2152 - val_loss: 2.3260 - val_accuracy: 0.1700\n",
            "Epoch 215/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1966 - accuracy: 0.2118 - val_loss: 2.3445 - val_accuracy: 0.1724\n",
            "Epoch 216/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1998 - accuracy: 0.2094 - val_loss: 2.3292 - val_accuracy: 0.1700\n",
            "Epoch 217/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1990 - accuracy: 0.2158 - val_loss: 2.3308 - val_accuracy: 0.1668\n",
            "Epoch 218/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1985 - accuracy: 0.2131 - val_loss: 2.3415 - val_accuracy: 0.1676\n",
            "Epoch 219/1000\n",
            "222/222 [==============================] - 2s 8ms/step - loss: 2.1981 - accuracy: 0.2097 - val_loss: 2.3377 - val_accuracy: 0.1652\n",
            "Epoch 220/1000\n",
            "222/222 [==============================] - 2s 8ms/step - loss: 2.1937 - accuracy: 0.2101 - val_loss: 2.3354 - val_accuracy: 0.1588\n",
            "Epoch 221/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1953 - accuracy: 0.2121 - val_loss: 2.3454 - val_accuracy: 0.1612\n",
            "Epoch 222/1000\n",
            "222/222 [==============================] - 2s 8ms/step - loss: 2.1962 - accuracy: 0.2114 - val_loss: 2.3457 - val_accuracy: 0.1636\n",
            "Epoch 223/1000\n",
            "222/222 [==============================] - 2s 8ms/step - loss: 2.1961 - accuracy: 0.2146 - val_loss: 2.3364 - val_accuracy: 0.1636\n",
            "Epoch 224/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1972 - accuracy: 0.2153 - val_loss: 2.3278 - val_accuracy: 0.1676\n",
            "Epoch 225/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1972 - accuracy: 0.2098 - val_loss: 2.3464 - val_accuracy: 0.1620\n",
            "Epoch 226/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1982 - accuracy: 0.2076 - val_loss: 2.3305 - val_accuracy: 0.1668\n",
            "Epoch 227/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1952 - accuracy: 0.2165 - val_loss: 2.3453 - val_accuracy: 0.1700\n",
            "Epoch 228/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1969 - accuracy: 0.2094 - val_loss: 2.3415 - val_accuracy: 0.1676\n",
            "Epoch 229/1000\n",
            "222/222 [==============================] - 1s 7ms/step - loss: 2.1969 - accuracy: 0.2080 - val_loss: 2.3398 - val_accuracy: 0.1652\n",
            "Epoch 230/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1932 - accuracy: 0.2121 - val_loss: 2.3421 - val_accuracy: 0.1636\n",
            "Epoch 231/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1931 - accuracy: 0.2128 - val_loss: 2.3411 - val_accuracy: 0.1660\n",
            "Epoch 232/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1903 - accuracy: 0.2180 - val_loss: 2.3423 - val_accuracy: 0.1724\n",
            "Epoch 233/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1960 - accuracy: 0.2127 - val_loss: 2.3335 - val_accuracy: 0.1692\n",
            "Epoch 234/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1893 - accuracy: 0.2142 - val_loss: 2.3323 - val_accuracy: 0.1668\n",
            "Epoch 235/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1917 - accuracy: 0.2105 - val_loss: 2.3427 - val_accuracy: 0.1612\n",
            "Epoch 236/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1886 - accuracy: 0.2089 - val_loss: 2.3418 - val_accuracy: 0.1652\n",
            "Epoch 237/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1931 - accuracy: 0.2090 - val_loss: 2.3307 - val_accuracy: 0.1612\n",
            "Epoch 238/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1904 - accuracy: 0.2166 - val_loss: 2.3424 - val_accuracy: 0.1692\n",
            "Epoch 239/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1926 - accuracy: 0.2160 - val_loss: 2.3415 - val_accuracy: 0.1620\n",
            "Epoch 240/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1916 - accuracy: 0.2135 - val_loss: 2.3348 - val_accuracy: 0.1708\n",
            "Epoch 241/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1897 - accuracy: 0.2141 - val_loss: 2.3537 - val_accuracy: 0.1660\n",
            "Epoch 242/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1902 - accuracy: 0.2170 - val_loss: 2.3555 - val_accuracy: 0.1532\n",
            "Epoch 243/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1930 - accuracy: 0.2132 - val_loss: 2.3467 - val_accuracy: 0.1676\n",
            "Epoch 244/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1892 - accuracy: 0.2214 - val_loss: 2.3497 - val_accuracy: 0.1612\n",
            "Epoch 245/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1905 - accuracy: 0.2129 - val_loss: 2.3409 - val_accuracy: 0.1580\n",
            "Epoch 246/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1922 - accuracy: 0.2173 - val_loss: 2.3400 - val_accuracy: 0.1588\n",
            "Epoch 247/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1894 - accuracy: 0.2148 - val_loss: 2.3435 - val_accuracy: 0.1604\n",
            "Epoch 248/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1879 - accuracy: 0.2128 - val_loss: 2.3483 - val_accuracy: 0.1580\n",
            "Epoch 249/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1859 - accuracy: 0.2124 - val_loss: 2.3454 - val_accuracy: 0.1596\n",
            "Epoch 250/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1898 - accuracy: 0.2131 - val_loss: 2.3580 - val_accuracy: 0.1764\n",
            "Epoch 251/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1919 - accuracy: 0.2107 - val_loss: 2.3341 - val_accuracy: 0.1684\n",
            "Epoch 252/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1883 - accuracy: 0.2141 - val_loss: 2.3454 - val_accuracy: 0.1668\n",
            "Epoch 253/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1898 - accuracy: 0.2131 - val_loss: 2.3454 - val_accuracy: 0.1588\n",
            "Epoch 254/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1869 - accuracy: 0.2162 - val_loss: 2.3295 - val_accuracy: 0.1628\n",
            "Epoch 255/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1902 - accuracy: 0.2142 - val_loss: 2.3532 - val_accuracy: 0.1612\n",
            "Epoch 256/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1878 - accuracy: 0.2177 - val_loss: 2.3530 - val_accuracy: 0.1580\n",
            "Epoch 257/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1884 - accuracy: 0.2155 - val_loss: 2.3502 - val_accuracy: 0.1644\n",
            "Epoch 258/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1896 - accuracy: 0.2131 - val_loss: 2.3473 - val_accuracy: 0.1636\n",
            "Epoch 259/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1876 - accuracy: 0.2177 - val_loss: 2.3552 - val_accuracy: 0.1588\n",
            "Epoch 260/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1878 - accuracy: 0.2152 - val_loss: 2.3557 - val_accuracy: 0.1604\n",
            "Epoch 261/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1830 - accuracy: 0.2167 - val_loss: 2.3523 - val_accuracy: 0.1620\n",
            "Epoch 262/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1875 - accuracy: 0.2160 - val_loss: 2.3529 - val_accuracy: 0.1620\n",
            "Epoch 263/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1870 - accuracy: 0.2160 - val_loss: 2.3494 - val_accuracy: 0.1692\n",
            "Epoch 264/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1863 - accuracy: 0.2096 - val_loss: 2.3582 - val_accuracy: 0.1660\n",
            "Epoch 265/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1841 - accuracy: 0.2177 - val_loss: 2.3536 - val_accuracy: 0.1532\n",
            "Epoch 266/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1849 - accuracy: 0.2162 - val_loss: 2.3580 - val_accuracy: 0.1588\n",
            "Epoch 267/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1846 - accuracy: 0.2170 - val_loss: 2.3519 - val_accuracy: 0.1620\n",
            "Epoch 268/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1846 - accuracy: 0.2153 - val_loss: 2.3538 - val_accuracy: 0.1596\n",
            "Epoch 269/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1836 - accuracy: 0.2122 - val_loss: 2.3577 - val_accuracy: 0.1652\n",
            "Epoch 270/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1823 - accuracy: 0.2136 - val_loss: 2.3681 - val_accuracy: 0.1540\n",
            "Epoch 271/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1820 - accuracy: 0.2182 - val_loss: 2.3454 - val_accuracy: 0.1620\n",
            "Epoch 272/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1822 - accuracy: 0.2189 - val_loss: 2.3631 - val_accuracy: 0.1660\n",
            "Epoch 273/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1849 - accuracy: 0.2124 - val_loss: 2.3517 - val_accuracy: 0.1572\n",
            "Epoch 274/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1810 - accuracy: 0.2205 - val_loss: 2.3579 - val_accuracy: 0.1660\n",
            "Epoch 275/1000\n",
            "222/222 [==============================] - 2s 7ms/step - loss: 2.1815 - accuracy: 0.2193 - val_loss: 2.3629 - val_accuracy: 0.1660\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1e8b725550>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "model.fit(train_X, train_y, validation_data=(test_X,test_y),epochs=1000,callbacks=[save_best, patience])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "FRuvGjLNCO8A"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "zisQgpJPqhgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3ea417-0ce4-4355-9708-8ce57576ea6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "\n",
        "for yhat in predictions:\n",
        "  pred.append(np.argmax(yhat))"
      ],
      "metadata": {
        "id": "e4TgUaMU-6f0"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual = []\n",
        "\n",
        "for y in test_y:\n",
        "  actual.append(np.argmax(y))"
      ],
      "metadata": {
        "id": "4Q1LFOBe_JxO"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "1mOKD09k_j0S"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(actual, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUy-c4dK_soD",
        "outputId": "d8301459-463a-444b-cb9e-20ff9c87a855"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16600159616919394"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVRJTGB1_89-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8RnOqTwSb53z"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMMvtE6K10nQSYXQWZdglN0",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}