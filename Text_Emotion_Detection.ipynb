{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi-11nav/Text-Emotion-Detection/blob/main/Text_Emotion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zofTXg4alSny"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WhgKucVla2i",
        "outputId": "0be8f94c-91f3-40bb-dbe3-a2aecb74b4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Text-Emotion-Detection'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 45 (delta 26), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (45/45), done.\n"
          ]
        }
      ],
      "source": [
        "# Cloning the github repository \n",
        "\n",
        "!git clone https://github.com/abhi-11nav/Text-Emotion-Detection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hKbC0BeildcI"
      },
      "outputs": [],
      "source": [
        "# Importing data\n",
        "\n",
        "data = pd.read_csv(\"/content/Text-Emotion-Detection/tweet_emotions.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Yu8taALUlofD",
        "outputId": "59bf7cb2-b7ac-4e5b-aa32-6ae802ce8f66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     tweet_id   sentiment                                            content\n",
              "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
              "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
              "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd5ad5bf-299a-45cb-b06b-cd666ebf0df4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1956967341</td>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1956967789</td>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1956968416</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd5ad5bf-299a-45cb-b06b-cd666ebf0df4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd5ad5bf-299a-45cb-b06b-cd666ebf0df4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd5ad5bf-299a-45cb-b06b-cd666ebf0df4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funeral ceremony...gloomy friday..."
      ],
      "metadata": {
        "id": "OLCfmZ18pXYF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TIUmyCIAmA-_"
      },
      "outputs": [],
      "source": [
        "# Let us drop the tweet id\n",
        "\n",
        "data.drop(\"tweet_id\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "uIDRz4D-mJXk",
        "outputId": "bb67852f-e960-4cc1-95de-00015159cb30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sentiment                                            content\n",
              "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2     sadness                Funeral ceremony...gloomy friday...\n",
              "3  enthusiasm               wants to hang out with friends SOON!\n",
              "4     neutral  @dannycastillo We want to trade with someone w..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32a90677-6d9e-42b4-9def-d203b23c7fd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32a90677-6d9e-42b4-9def-d203b23c7fd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32a90677-6d9e-42b4-9def-d203b23c7fd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32a90677-6d9e-42b4-9def-d203b23c7fd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeEFLErwmZxK",
        "outputId": "c370daff-014f-4730-f77b-5b710f7c3918"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment    False\n",
              "content      False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Let us check if the tweet has any missing values \n",
        "\n",
        "data.isna().any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syZBYwVdmubC"
      },
      "source": [
        "No missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLiURfjqmszA",
        "outputId": "a90147d7-3a31-4848-b984-5e5f7a53c1bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "boredom        179\n",
              "anger          110\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Let us check the number of categories in sentiment variable\n",
        "\n",
        "data['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRYV6lDBnsw7"
      },
      "source": [
        "The data seems imbalanced. Let us deal with it after a bit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "4ITV_GjAnT70",
        "outputId": "c92da7aa-6666-4c4e-ddb2-a6c918f86a2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =['"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Let us look at the sentences\n",
        "\n",
        "data['content'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "LqKVBAqVoMhn",
        "outputId": "94480bee-a052-4b5d-d4b8-6b117c78036d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Layin n bed with a headache  ughhhh...waitin on your call...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data['content'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9VKL5TVpDiw"
      },
      "source": [
        "Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMD6rP6Hr_xt",
        "outputId": "bb2dec6e-beb8-497d-adda-f19e8dbc996c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# Importing libraries\n",
        "\n",
        "import re \n",
        "\n",
        "import nltk \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hG_T2DWSo925"
      },
      "outputs": [],
      "source": [
        "def text_preprocess(dataset,list_name):\n",
        "  \n",
        "  for i in range(dataset.shape[0]):\n",
        "    list_name.append(re.sub('[^a-zA-Z]',' ',str(dataset.iloc[i,1])))\n",
        "\n",
        "  print(\"Number and other symbols eliminated from the text\")\n",
        "\n",
        "  # String spacing \n",
        "  for x in range(len(list_name)):\n",
        "    list_name[x] = \" \".join(y for y in str(list_name[x]).split()).lower()\n",
        "\n",
        "  print(\"Text reorganized and converted to small letter\")\n",
        "  \n",
        "  for index in range(len(list_name)):\n",
        "    temp_list= []\n",
        "    # Lemmatization\n",
        "    for word in list_name[index].split():\n",
        "      if word not in stopwords.words('english'):\n",
        "        temp_list.append(word)\n",
        "    list_name[index] = \" \".join(lemmatizer.lemmatize(words) for words in temp_list )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiOLAlRoo952",
        "outputId": "0bb7a3cb-3349-46c3-bd44-c82a8c475736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number and other symbols eliminated from the text\n",
            "Text reorganized and converted to small letter\n"
          ]
        }
      ],
      "source": [
        "sentences = []\n",
        "\n",
        "text_preprocess(data,sentences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_data = pd.concat([pd.DataFrame(np.array(sentences), columns=[\"Content\"]), data['sentiment']], axis=1)"
      ],
      "metadata": {
        "id": "rFIZ0Mdz5f6s"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "940QFH6M-rOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WORD2VEC MANUAL**"
      ],
      "metadata": {
        "id": "kpAFUbh3-rTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying one hot encoding '"
      ],
      "metadata": {
        "id": "dtZwnMj55q_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import one_hot"
      ],
      "metadata": {
        "id": "JDhVeYD15pGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "F60GyyZe5pJP",
        "outputId": "3c90138d-4f87-439f-b503-aa64c9758037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Content   sentiment\n",
              "0  tiffanylue know listenin bad habit earlier sta...       empty\n",
              "1            layin n bed headache ughhhh waitin call     sadness\n",
              "2                     funeral ceremony gloomy friday     sadness\n",
              "3                              want hang friend soon  enthusiasm\n",
              "4  dannycastillo want trade someone houston ticke...     neutral"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12c4f6f4-4226-4021-bc77-b4fd685025fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tiffanylue know listenin bad habit earlier sta...</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>layin n bed headache ughhhh waitin call</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>want hang friend soon</td>\n",
              "      <td>enthusiasm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dannycastillo want trade someone houston ticke...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12c4f6f4-4226-4021-bc77-b4fd685025fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12c4f6f4-4226-4021-bc77-b4fd685025fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12c4f6f4-4226-4021-bc77-b4fd685025fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List conatining sentences\n",
        "\n",
        "sentences = [sent for sent in p_data[\"Content\"]]"
      ],
      "metadata": {
        "id": "HjGQSxno6zjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique words\n",
        "\n",
        "unique_word_list = []\n",
        "\n",
        "for index in range(len(sentences)):\n",
        "  [unique_word_list.append(w) for w in sentences[index].split()]\n",
        "\n",
        "\n",
        "unique_words = list(set(unique_word_list))\n",
        "\n",
        "print(len(unique_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gCVlTw85pME",
        "outputId": "5529bde0-1b7b-4fc0-ee24-bbac1f126262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary_size \n",
        "\n",
        "vocab_size = len(unique_words)"
      ],
      "metadata": {
        "id": "66jByVww6hVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoder = [one_hot(words, vocab_size) for words in sentences]"
      ],
      "metadata": {
        "id": "k3NdRxto6hYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoder[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO94Fpr96hdE",
        "outputId": "662fceaf-db0f-4c0b-e23f-fda7fb0dfd9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37387, 32288, 33984, 12232, 17768, 4014, 42550, 34624, 26440]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding"
      ],
      "metadata": {
        "id": "Ww__8k1L70kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "XGLyqS8S6hgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finidng the sentence with maximum length\n",
        "\n",
        "max_length = 0\n",
        "\n",
        "for sent in sentences:\n",
        "  if len(sent) > max_length:\n",
        "    max_length = len(sent)"
      ],
      "metadata": {
        "id": "LtF41jcS6hjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiHYk52C6hl6",
        "outputId": "28522339-1fb3-41bc-9c61-99b85986e8cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_docs = pad_sequences(one_hot_encoder, padding='pre', maxlen=max_length)"
      ],
      "metadata": {
        "id": "JbXWUakf6hpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTkZ8QxF6hrH",
        "outputId": "0f636f7d-69d6-45ef-c06d-9abc1d69475e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0, 37387, 32288,\n",
              "       33984, 12232, 17768,  4014, 42550, 34624, 26440], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting values into vector features"
      ],
      "metadata": {
        "id": "VDlpHgY_-njF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.models import Model, Sequential"
      ],
      "metadata": {
        "id": "QLDUCzf1-9sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_dimension = 50"
      ],
      "metadata": {
        "id": "ZA-mmVyp6huY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "lxb1Bn9J6hx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding layer and LSTM RNN Model"
      ],
      "metadata": {
        "id": "aXmL0-daK_uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Embedding(vocab_size, output_dim = vector_dimension,input_length=max_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(13, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "6WvluKAp6hz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "checkpoint = EarlyStopping(patience = 20)"
      ],
      "metadata": {
        "id": "hZYxZtt_jy4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(embedded_docs, y, validation_split=0.15, epochs = 100,callbacks=checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7SfPZa4jhax",
        "outputId": "76017393-beb0-4fc4-a1f3-471fe127108f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding_1/embeddings:0', 'lstm_2/lstm_cell_2/kernel:0', 'lstm_2/lstm_cell_2/recurrent_kernel:0', 'lstm_2/lstm_cell_2/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1063/1063 [==============================] - 16s 12ms/step - loss: 2.1307 - accuracy: 0.2295 - val_loss: 2.2517 - val_accuracy: 0.1035\n",
            "Epoch 2/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1302 - accuracy: 0.2296 - val_loss: 2.2562 - val_accuracy: 0.2317\n",
            "Epoch 3/100\n",
            "1063/1063 [==============================] - 13s 12ms/step - loss: 2.1305 - accuracy: 0.2300 - val_loss: 2.2498 - val_accuracy: 0.1035\n",
            "Epoch 4/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1303 - accuracy: 0.2308 - val_loss: 2.2485 - val_accuracy: 0.1035\n",
            "Epoch 5/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1301 - accuracy: 0.2300 - val_loss: 2.2617 - val_accuracy: 0.1035\n",
            "Epoch 6/100\n",
            "1063/1063 [==============================] - 12s 12ms/step - loss: 2.1302 - accuracy: 0.2295 - val_loss: 2.2644 - val_accuracy: 0.1035\n",
            "Epoch 7/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1302 - accuracy: 0.2291 - val_loss: 2.2630 - val_accuracy: 0.1035\n",
            "Epoch 8/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1300 - accuracy: 0.2296 - val_loss: 2.2642 - val_accuracy: 0.1035\n",
            "Epoch 9/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1303 - accuracy: 0.2302 - val_loss: 2.2671 - val_accuracy: 0.1035\n",
            "Epoch 10/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1302 - accuracy: 0.2303 - val_loss: 2.2741 - val_accuracy: 0.1035\n",
            "Epoch 11/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1303 - accuracy: 0.2285 - val_loss: 2.2702 - val_accuracy: 0.1035\n",
            "Epoch 12/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1303 - accuracy: 0.2301 - val_loss: 2.2664 - val_accuracy: 0.1035\n",
            "Epoch 13/100\n",
            "1063/1063 [==============================] - 12s 12ms/step - loss: 2.1298 - accuracy: 0.2304 - val_loss: 2.2864 - val_accuracy: 0.1035\n",
            "Epoch 14/100\n",
            "1063/1063 [==============================] - 13s 12ms/step - loss: 2.1302 - accuracy: 0.2304 - val_loss: 2.2547 - val_accuracy: 0.1035\n",
            "Epoch 15/100\n",
            "1063/1063 [==============================] - 12s 12ms/step - loss: 2.1300 - accuracy: 0.2290 - val_loss: 2.2579 - val_accuracy: 0.1035\n",
            "Epoch 16/100\n",
            "1063/1063 [==============================] - 13s 12ms/step - loss: 2.1298 - accuracy: 0.2296 - val_loss: 2.2664 - val_accuracy: 0.1035\n",
            "Epoch 17/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1296 - accuracy: 0.2303 - val_loss: 2.2588 - val_accuracy: 0.1035\n",
            "Epoch 18/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1299 - accuracy: 0.2289 - val_loss: 2.2594 - val_accuracy: 0.1035\n",
            "Epoch 19/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1300 - accuracy: 0.2299 - val_loss: 2.2707 - val_accuracy: 0.1035\n",
            "Epoch 20/100\n",
            "1063/1063 [==============================] - 12s 12ms/step - loss: 2.1300 - accuracy: 0.2304 - val_loss: 2.2714 - val_accuracy: 0.1035\n",
            "Epoch 21/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1301 - accuracy: 0.2308 - val_loss: 2.2777 - val_accuracy: 0.1035\n",
            "Epoch 22/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1298 - accuracy: 0.2305 - val_loss: 2.2636 - val_accuracy: 0.1035\n",
            "Epoch 23/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1298 - accuracy: 0.2299 - val_loss: 2.2610 - val_accuracy: 0.1035\n",
            "Epoch 24/100\n",
            "1063/1063 [==============================] - 12s 11ms/step - loss: 2.1298 - accuracy: 0.2295 - val_loss: 2.2610 - val_accuracy: 0.1035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jrTMnFMiM_HG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af68d66-6a8e-4291-fa73-a7aeab1fe2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 133, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "9TkJwIhHLIhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GaussianNB()"
      ],
      "metadata": {
        "id": "5xln-IPELIk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=0.1,random_state=101)"
      ],
      "metadata": {
        "id": "wUtx6seAoz2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_y)"
      ],
      "metadata": {
        "id": "f23ZfokRLIn4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "dc2c050d-a9b5-4328-9b43-4221aa95fa36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-92379a943613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         return self._partial_fit(\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_refit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         )\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_partial_fit_first_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = np.array(train_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFQte-cnqWL7",
        "outputId": "00097ed3-6a09-4eba-9c1a-0c1ea9ebab3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = np.array([x.reshape(-1,1) for x in train_X])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tmJOV1Jqhv3",
        "outputId": "c0b6429b-ce6f-4912-849c-d59282b44b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DYpA1tHAqh2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_X)"
      ],
      "metadata": {
        "id": "yvSjiNYf6h15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "lUOrNWbH6h4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(test_y, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LptD70mjpF8g",
        "outputId": "a145053a-072e-493f-d66f-532bca0458ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8BIJb_7pF_q",
        "outputId": "f6b5b1d0-ba9f-40cf-fcdd-03fcc09b96f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lknjHGaRpGCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P0I34fKVpGFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w3BpfwkspGIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_6z1WOXKbW5"
      },
      "source": [
        "Text preprocessing done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dndtBo0EUtUN"
      },
      "source": [
        "Converting text to vectors \n",
        "\n",
        "Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz-Kj1N0Uwgr",
        "outputId": "8d962850-e1b5-40b0-9572-43d1f0065968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "import gensim\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5bKDKJyWx50",
        "outputId": "6584ca38-8480-4cb8-869a-1f59382cc011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40000  length of sentences\n"
          ]
        }
      ],
      "source": [
        "# Words list\n",
        "\n",
        "words_list = []\n",
        "\n",
        "# looping through to append words\n",
        "for index in range(len(sentences)):\n",
        "  words_list.append(nltk.word_tokenize(sentences[index]))\n",
        "\n",
        "print(len(words_list),\" length of sentences\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty_lists = []\n",
        "\n",
        "for i,wl in enumerate(words_list):\n",
        "  if not wl:\n",
        "    empty_lists.append(i)\n",
        "\n",
        "print(\"The number of empty lists are: \", len(empty_lists))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5cz9ytD_0x7",
        "outputId": "af20c54d-081a-423a-cb9a-6f67427632b1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of empty lists are:  21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there are 21 empty lists. We will combine them with the labels and drop the 21 rows"
      ],
      "metadata": {
        "id": "83iHg3J0Agv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us combine the dataset and get rid of any null values that may have occured after preprocessing\n",
        "\n",
        "preprocessed_data = pd.concat([pd.DataFrame(np.array(words_list)),pd.DataFrame(data['sentiment'])], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJUqQDY6AUY1",
        "outputId": "dc45e87c-aeef-4980-a150-e9c9662a5fd2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for null values \n",
        "\n",
        "preprocessed_data.isna().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f6mabsOAz2D",
        "outputId": "8ea94075-1bf9-4f6e-ff65-36a85d662bd9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            False\n",
              "sentiment    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We have empty lists that we have to get rid of and we have the indexes of those lists store in empty_lists list\n",
        "\n",
        "# Verifying elemnts from the list\n",
        "\n",
        "for indexes in empty_lists:\n",
        "  print(preprocessed_data.iloc[indexes,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHC82BgeAz5f",
        "outputId": "b8a80899-6837-454b-8337-471ef978f8b8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There we go, our empty lists. "
      ],
      "metadata": {
        "id": "MY8pOwQhC0SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_data.drop(empty_lists, axis=0, inplace=True)"
      ],
      "metadata": {
        "id": "1IarhUKTC5Q1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_lists = [lists for lists in preprocessed_data.iloc[:,0]]"
      ],
      "metadata": {
        "id": "9Re36EArC5Wv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "H1zdnQ9KUwkB"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.Word2Vec(words_list, window=5, min_count = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifTQTZJnUwmX",
        "outputId": "1f6427be-71d1-4cf9-a8e5-21483eb786e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/39979 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "100%|██████████| 39979/39979 [00:20<00:00, 1946.58it/s]\n"
          ]
        }
      ],
      "source": [
        "# Empty list \n",
        "X = []\n",
        "\n",
        "# Looping though words\n",
        "for words in tqdm(word_lists):\n",
        "  X.append(np.mean([model.wv[word] for word in words if word in model.wv.index2word], axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coverting them to arrays\n",
        "\n",
        "X = np.array(X)\n",
        "y = preprocessed_data['sentiment']"
      ],
      "metadata": {
        "id": "6k7AnxBbQuuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee4b3bfa-fb3f-4b8a-fd46-da910239505b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "corresponding_num = []\n",
        "\n",
        "for ind,lab in enumerate(y.unique()):\n",
        "  labels.append(lab)\n",
        "  corresponding_num.append(ind)"
      ],
      "metadata": {
        "id": "DCShbT5-Eigt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = [val for val in y]"
      ],
      "metadata": {
        "id": "f_HgyyO9I5AM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,value in enumerate(encodings):\n",
        "  for ind,unique in enumerate(labels):\n",
        "    if value==unique:\n",
        "      encodings[i] = ind"
      ],
      "metadata": {
        "id": "-rLjCOWcJINa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = np.array(encodings)"
      ],
      "metadata": {
        "id": "99rsc72XJIU6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = encodings"
      ],
      "metadata": {
        "id": "YbYXCJodJIfW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking types"
      ],
      "metadata": {
        "id": "J8cABT2dFkCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting all the arrays to same data type\n",
        "\n",
        "X = np.array([val.astype(np.float64) for val in X])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5dYV-1CFjOq",
        "outputId": "57351f10-ceb0-444e-d3fa-ecf5363c1a93"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for null values in the array"
      ],
      "metadata": {
        "id": "Nhc25PhbM6k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X).isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEArqpIDM5R-",
        "outputId": "5ac6486f-de61-4462-b9df-3ed48dab85ba"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    227\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Found 227 null values"
      ],
      "metadata": {
        "id": "amLM-wY8NA6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us combine the dataset and get rid of any null values that may have occured after preprocessing\n",
        "\n",
        "vector_data = pd.concat([pd.DataFrame(X),pd.DataFrame(y)], axis=1)"
      ],
      "metadata": {
        "id": "67qxnjvcM5XQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "yG3k9XQPNHsp",
        "outputId": "c42d6d79-9a2a-421c-fd7d-a441e5da4448"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0  0\n",
              "0  [0.5506941080093384, 0.003065967932343483, -0....  0\n",
              "1  [0.4870327413082123, 0.017306378111243248, -0....  1\n",
              "2  [0.31976938247680664, -0.0656706765294075, -0....  1\n",
              "3  [0.7915036678314209, -0.07395879179239273, -0....  2\n",
              "4  [0.6090165972709656, 0.023950688540935516, -0....  3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dab85c6a-beb2-4492-9f9d-5ceca62a5833\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.5506941080093384, 0.003065967932343483, -0....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.4870327413082123, 0.017306378111243248, -0....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.31976938247680664, -0.0656706765294075, -0....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.7915036678314209, -0.07395879179239273, -0....</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.6090165972709656, 0.023950688540935516, -0....</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dab85c6a-beb2-4492-9f9d-5ceca62a5833')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dab85c6a-beb2-4492-9f9d-5ceca62a5833 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dab85c6a-beb2-4492-9f9d-5ceca62a5833');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_data.isna().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqjqVQLPNHvB",
        "outputId": "d5899ad0-c467-468c-80ee-7a0d6694552a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     True\n",
              "0    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping all the null values"
      ],
      "metadata": {
        "id": "uibrYSgwNZqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "IzaBHu7SNHy-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoPqfsDLNH1D",
        "outputId": "880c4d4f-d8bd-4157-c8ee-477d062ef89d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39752, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "adcOf2r7Ipg9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([feat for feat in vector_data.iloc[:,0]])\n",
        "y = np.array([label for label in vector_data.iloc[:,1]])"
      ],
      "metadata": {
        "id": "TTVYNjgtNH5A"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X,y, train_size = 0.93, random_state= 12)"
      ],
      "metadata": {
        "id": "yJpmXLdErQ5O"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "RFVzraZyx777"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "\n",
        "gnb.fit(train_X, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaRfyukTL4Gc",
        "outputId": "130eb91a-de4f-4fa6-f57f-bbd4222d590a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = gnb.predict(test_X)"
      ],
      "metadata": {
        "id": "7qqIIkV5rRGT"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "OlVYC7SsOQ_L"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = accuracy_score(test_y, predictions)"
      ],
      "metadata": {
        "id": "tHrQlJJurRLM"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"And the final score is ...... ..... ...\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv2YvqIHs31U",
        "outputId": "5c011c23-8750-4d6f-ba42-94889e1ecc0c"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And the final score is ...... ..... ... 0.0693496227093065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "id": "XO6JNpqds4EL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1428b10e-d71c-4a08-f35e-ccfac2c951f6"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36969, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.shape"
      ],
      "metadata": {
        "id": "mw19XNuds4Ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58507ad2-f61c-47b8-ede8-4bbfbfb3d677"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36969,)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting to categories"
      ],
      "metadata": {
        "id": "eWwLHCjzzs4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "PwTWvlVCzV4o"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = to_categorical(train_y,13)"
      ],
      "metadata": {
        "id": "kBvpSoXWzV8-"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Covertiing test_y to binary \n",
        "\n",
        "test_y = to_categorical(test_y,13)"
      ],
      "metadata": {
        "id": "UBStd_0dEIHH"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ_uu-D8Kdh8"
      },
      "source": [
        "## LSTM RNN MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB9_UQpFN-iD"
      },
      "source": [
        "Implementing Bi-directional Long short term Memory recurrent neural network "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "5XctiZrBJqNu"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries\n",
        "\n",
        "import tensorflow \n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers import Dense, Flatten, Input, LSTM, Bidirectional, Embedding, Dropout, CuDNNLSTM\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FX_cBlE8iHN",
        "outputId": "4babb8c0-7d43-4115-91ca-3845a28be56c"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fluctuations are normal within certain limits and depend on the fact that you use a heuristic method but in your case they are excessive. Despite all the performance takes a definite direction and therefore the system works. From the graphs you have posted, the problem depends on your data so it's a difficult training. If you have already tried to change the learning rate try to change training algorithm. You would agree to test your data: first compute the Bayes error rate using a KNN (use the trick regression in case you need), in this way you can check whether the input data contain all the information you need. Then try the LSTM without the validation or dropout to verify that it has the ability to achieve the result for you necessary. If the training algorithm is not suitable you should have the same problems even without the validation or dropout. Just at the end adjust the training and the validation size to get the best result in the test set. Statistical learning theory is not a topic that can be talked about at one time, we must proceed step by step.\n"
      ],
      "metadata": {
        "id": "ANsSvX-5HvnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "source :https://stats.stackexchange.com/questions/345990/why-does-the-loss-accuracy-fluctuate-during-the-training-keras-lstm"
      ],
      "metadata": {
        "id": "cdaMQD09qzdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(100,1))\n",
        "lstm = CuDNNLSTM(100, return_sequences=True)(input)\n",
        "dropout = Dropout(0.2)(lstm)\n",
        "lstm2 = CuDNNLSTM(100)(dropout)\n",
        "dropout2 = Dropout(0.2)(lstm2)\n",
        "lstm3 = Dense(100, activation=\"relu\")(dropout2)\n",
        "dropout3 = Dropout(0.2)(lstm3)\n",
        "prediction = Dense(13, activation=\"softmax\")(dropout3)"
      ],
      "metadata": {
        "id": "YJvqoSDsy9-Q"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "\n",
        "model = Model(inputs = input, outputs = prediction)"
      ],
      "metadata": {
        "id": "zS1hnHUt6ZNb"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSAZhDi-6e3b",
        "outputId": "892c0daf-2032-4c2d-ba9e-19812f4a69fc"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 100, 1)]          0         \n",
            "                                                                 \n",
            " cu_dnnlstm (CuDNNLSTM)      (None, 100, 100)          41200     \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 100, 100)          0         \n",
            "                                                                 \n",
            " cu_dnnlstm_1 (CuDNNLSTM)    (None, 100)               80800     \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 13)                1313      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,413\n",
            "Trainable params: 133,413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the learning rate for the optimizer. \n",
        "\n",
        "adam_optimizer = keras.optimizers.Adam(learning_rate=1e-3, decay=1e-6)\n",
        "\n",
        "# Compiling the model\n",
        "\n",
        "model.compile(optimizer=adam_optimizer, loss=\"categorical_crossentropy\", metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "OoEALr471j2b"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras callbacks"
      ],
      "metadata": {
        "id": "uaxBoFlHAySp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "YAjvM2gpA6KC"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_best = ModelCheckpoint(\"lstm_model.h5\", save_best_only=True)"
      ],
      "metadata": {
        "id": "RwBTC950A6rE"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_ZENR97Dzs7",
        "outputId": "dbfd8944-4494-4e3e-952a-eb2ff05bda57"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36969, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwqYrrw2D2GA",
        "outputId": "82fe766e-9982-4890-cf75-67fc31608dd4"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36969, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l51f7vXD2JZ",
        "outputId": "ab477fde-6f73-4f4f-d750-965e9345c190"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2783, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PogsbxKnD2M4",
        "outputId": "dc753dff-95f6-4408-96da-ac421b2eb84c"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2783, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_y, validation_data=(test_X,test_y),epochs=1000,callbacks=[save_best])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qwu7JZws1tJR",
        "outputId": "eef938b6-86f8-468a-8f3f-c27be2e21f80"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0315 - accuracy: 0.2876 - val_loss: 2.0724 - val_accuracy: 0.2799\n",
            "Epoch 2/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0300 - accuracy: 0.2888 - val_loss: 2.0683 - val_accuracy: 0.2878\n",
            "Epoch 3/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 2.0301 - accuracy: 0.2886 - val_loss: 2.0757 - val_accuracy: 0.2853\n",
            "Epoch 4/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0295 - accuracy: 0.2840 - val_loss: 2.0766 - val_accuracy: 0.2831\n",
            "Epoch 5/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0274 - accuracy: 0.2865 - val_loss: 2.0745 - val_accuracy: 0.2810\n",
            "Epoch 6/1000\n",
            "1156/1156 [==============================] - 12s 11ms/step - loss: 2.0282 - accuracy: 0.2878 - val_loss: 2.0830 - val_accuracy: 0.2878\n",
            "Epoch 7/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0263 - accuracy: 0.2873 - val_loss: 2.0763 - val_accuracy: 0.2860\n",
            "Epoch 8/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0247 - accuracy: 0.2895 - val_loss: 2.0800 - val_accuracy: 0.2796\n",
            "Epoch 9/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0242 - accuracy: 0.2917 - val_loss: 2.0774 - val_accuracy: 0.2864\n",
            "Epoch 10/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0221 - accuracy: 0.2885 - val_loss: 2.0704 - val_accuracy: 0.2864\n",
            "Epoch 11/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 2.0212 - accuracy: 0.2927 - val_loss: 2.0805 - val_accuracy: 0.2896\n",
            "Epoch 12/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0207 - accuracy: 0.2911 - val_loss: 2.0694 - val_accuracy: 0.2889\n",
            "Epoch 13/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0190 - accuracy: 0.2916 - val_loss: 2.0728 - val_accuracy: 0.2875\n",
            "Epoch 14/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 2.0176 - accuracy: 0.2903 - val_loss: 2.0808 - val_accuracy: 0.2842\n",
            "Epoch 15/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0179 - accuracy: 0.2923 - val_loss: 2.0812 - val_accuracy: 0.2871\n",
            "Epoch 16/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0170 - accuracy: 0.2927 - val_loss: 2.0798 - val_accuracy: 0.2763\n",
            "Epoch 17/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0154 - accuracy: 0.2899 - val_loss: 2.0789 - val_accuracy: 0.2796\n",
            "Epoch 18/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0153 - accuracy: 0.2934 - val_loss: 2.0730 - val_accuracy: 0.2814\n",
            "Epoch 19/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0145 - accuracy: 0.2918 - val_loss: 2.0742 - val_accuracy: 0.2831\n",
            "Epoch 20/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0118 - accuracy: 0.2931 - val_loss: 2.0737 - val_accuracy: 0.2946\n",
            "Epoch 21/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 2.0097 - accuracy: 0.2914 - val_loss: 2.0793 - val_accuracy: 0.2853\n",
            "Epoch 22/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0129 - accuracy: 0.2940 - val_loss: 2.0837 - val_accuracy: 0.2860\n",
            "Epoch 23/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0108 - accuracy: 0.2942 - val_loss: 2.0835 - val_accuracy: 0.2806\n",
            "Epoch 24/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 2.0079 - accuracy: 0.2939 - val_loss: 2.0826 - val_accuracy: 0.2954\n",
            "Epoch 25/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0081 - accuracy: 0.2954 - val_loss: 2.0764 - val_accuracy: 0.2878\n",
            "Epoch 26/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0077 - accuracy: 0.2948 - val_loss: 2.0756 - val_accuracy: 0.2878\n",
            "Epoch 27/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0051 - accuracy: 0.2935 - val_loss: 2.0808 - val_accuracy: 0.2928\n",
            "Epoch 28/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 2.0045 - accuracy: 0.2955 - val_loss: 2.0756 - val_accuracy: 0.2896\n",
            "Epoch 29/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0036 - accuracy: 0.2929 - val_loss: 2.0819 - val_accuracy: 0.2882\n",
            "Epoch 30/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0020 - accuracy: 0.2937 - val_loss: 2.0831 - val_accuracy: 0.2875\n",
            "Epoch 31/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 2.0012 - accuracy: 0.2968 - val_loss: 2.0809 - val_accuracy: 0.2842\n",
            "Epoch 32/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 2.0014 - accuracy: 0.2973 - val_loss: 2.0887 - val_accuracy: 0.2817\n",
            "Epoch 33/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9982 - accuracy: 0.2970 - val_loss: 2.0805 - val_accuracy: 0.2828\n",
            "Epoch 34/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9997 - accuracy: 0.2981 - val_loss: 2.0917 - val_accuracy: 0.2839\n",
            "Epoch 35/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9967 - accuracy: 0.2979 - val_loss: 2.0743 - val_accuracy: 0.2900\n",
            "Epoch 36/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9961 - accuracy: 0.2963 - val_loss: 2.0842 - val_accuracy: 0.2828\n",
            "Epoch 37/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9947 - accuracy: 0.2993 - val_loss: 2.0934 - val_accuracy: 0.2896\n",
            "Epoch 38/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.9962 - accuracy: 0.2970 - val_loss: 2.0933 - val_accuracy: 0.2932\n",
            "Epoch 39/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9965 - accuracy: 0.2979 - val_loss: 2.0845 - val_accuracy: 0.2939\n",
            "Epoch 40/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9928 - accuracy: 0.2965 - val_loss: 2.0857 - val_accuracy: 0.2875\n",
            "Epoch 41/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9908 - accuracy: 0.2981 - val_loss: 2.0876 - val_accuracy: 0.2893\n",
            "Epoch 42/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9894 - accuracy: 0.3015 - val_loss: 2.0946 - val_accuracy: 0.2871\n",
            "Epoch 43/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9878 - accuracy: 0.3008 - val_loss: 2.0963 - val_accuracy: 0.2853\n",
            "Epoch 44/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9874 - accuracy: 0.3024 - val_loss: 2.0811 - val_accuracy: 0.2860\n",
            "Epoch 45/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9847 - accuracy: 0.2986 - val_loss: 2.0999 - val_accuracy: 0.2900\n",
            "Epoch 46/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9847 - accuracy: 0.3024 - val_loss: 2.0983 - val_accuracy: 0.2882\n",
            "Epoch 47/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9834 - accuracy: 0.3027 - val_loss: 2.0897 - val_accuracy: 0.2925\n",
            "Epoch 48/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9825 - accuracy: 0.3011 - val_loss: 2.0941 - val_accuracy: 0.2889\n",
            "Epoch 49/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9805 - accuracy: 0.3013 - val_loss: 2.1028 - val_accuracy: 0.2914\n",
            "Epoch 50/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9776 - accuracy: 0.3027 - val_loss: 2.0923 - val_accuracy: 0.2882\n",
            "Epoch 51/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9797 - accuracy: 0.3007 - val_loss: 2.0978 - val_accuracy: 0.2788\n",
            "Epoch 52/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.9765 - accuracy: 0.3031 - val_loss: 2.1000 - val_accuracy: 0.2860\n",
            "Epoch 53/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9758 - accuracy: 0.3051 - val_loss: 2.0964 - val_accuracy: 0.2975\n",
            "Epoch 54/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9765 - accuracy: 0.3053 - val_loss: 2.0948 - val_accuracy: 0.2871\n",
            "Epoch 55/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9740 - accuracy: 0.3034 - val_loss: 2.1164 - val_accuracy: 0.2864\n",
            "Epoch 56/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9722 - accuracy: 0.3042 - val_loss: 2.1025 - val_accuracy: 0.2849\n",
            "Epoch 57/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9716 - accuracy: 0.3055 - val_loss: 2.1130 - val_accuracy: 0.2799\n",
            "Epoch 58/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9679 - accuracy: 0.3053 - val_loss: 2.1165 - val_accuracy: 0.2824\n",
            "Epoch 59/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.9680 - accuracy: 0.3050 - val_loss: 2.1116 - val_accuracy: 0.2785\n",
            "Epoch 60/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9682 - accuracy: 0.3030 - val_loss: 2.1247 - val_accuracy: 0.2831\n",
            "Epoch 61/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9657 - accuracy: 0.3038 - val_loss: 2.0949 - val_accuracy: 0.2871\n",
            "Epoch 62/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9649 - accuracy: 0.3067 - val_loss: 2.1168 - val_accuracy: 0.2846\n",
            "Epoch 63/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9627 - accuracy: 0.3079 - val_loss: 2.1209 - val_accuracy: 0.2885\n",
            "Epoch 64/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9625 - accuracy: 0.3077 - val_loss: 2.1166 - val_accuracy: 0.2875\n",
            "Epoch 65/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9634 - accuracy: 0.3059 - val_loss: 2.1187 - val_accuracy: 0.2893\n",
            "Epoch 66/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9611 - accuracy: 0.3080 - val_loss: 2.1193 - val_accuracy: 0.2817\n",
            "Epoch 67/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9569 - accuracy: 0.3075 - val_loss: 2.1133 - val_accuracy: 0.2921\n",
            "Epoch 68/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9590 - accuracy: 0.3100 - val_loss: 2.1166 - val_accuracy: 0.2846\n",
            "Epoch 69/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9556 - accuracy: 0.3087 - val_loss: 2.1269 - val_accuracy: 0.2900\n",
            "Epoch 70/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9554 - accuracy: 0.3113 - val_loss: 2.1234 - val_accuracy: 0.2928\n",
            "Epoch 71/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9534 - accuracy: 0.3106 - val_loss: 2.1264 - val_accuracy: 0.2831\n",
            "Epoch 72/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9511 - accuracy: 0.3109 - val_loss: 2.1255 - val_accuracy: 0.2939\n",
            "Epoch 73/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9537 - accuracy: 0.3099 - val_loss: 2.1423 - val_accuracy: 0.2853\n",
            "Epoch 74/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9490 - accuracy: 0.3118 - val_loss: 2.1233 - val_accuracy: 0.2889\n",
            "Epoch 75/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9487 - accuracy: 0.3108 - val_loss: 2.1105 - val_accuracy: 0.2900\n",
            "Epoch 76/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9440 - accuracy: 0.3121 - val_loss: 2.1354 - val_accuracy: 0.2857\n",
            "Epoch 77/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9448 - accuracy: 0.3122 - val_loss: 2.1249 - val_accuracy: 0.2882\n",
            "Epoch 78/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9451 - accuracy: 0.3125 - val_loss: 2.1363 - val_accuracy: 0.2810\n",
            "Epoch 79/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9401 - accuracy: 0.3143 - val_loss: 2.1359 - val_accuracy: 0.2896\n",
            "Epoch 80/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9417 - accuracy: 0.3113 - val_loss: 2.1351 - val_accuracy: 0.2914\n",
            "Epoch 81/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9406 - accuracy: 0.3152 - val_loss: 2.1338 - val_accuracy: 0.2796\n",
            "Epoch 82/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9395 - accuracy: 0.3159 - val_loss: 2.1508 - val_accuracy: 0.2839\n",
            "Epoch 83/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9362 - accuracy: 0.3157 - val_loss: 2.1254 - val_accuracy: 0.2824\n",
            "Epoch 84/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9355 - accuracy: 0.3161 - val_loss: 2.1453 - val_accuracy: 0.2853\n",
            "Epoch 85/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9340 - accuracy: 0.3158 - val_loss: 2.1527 - val_accuracy: 0.2824\n",
            "Epoch 86/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.9367 - accuracy: 0.3150 - val_loss: 2.1477 - val_accuracy: 0.2846\n",
            "Epoch 87/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9329 - accuracy: 0.3186 - val_loss: 2.1476 - val_accuracy: 0.2842\n",
            "Epoch 88/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9296 - accuracy: 0.3184 - val_loss: 2.1528 - val_accuracy: 0.2821\n",
            "Epoch 89/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9297 - accuracy: 0.3168 - val_loss: 2.1629 - val_accuracy: 0.2831\n",
            "Epoch 90/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9278 - accuracy: 0.3173 - val_loss: 2.1638 - val_accuracy: 0.2871\n",
            "Epoch 91/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9292 - accuracy: 0.3146 - val_loss: 2.1459 - val_accuracy: 0.2846\n",
            "Epoch 92/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9243 - accuracy: 0.3191 - val_loss: 2.1715 - val_accuracy: 0.2864\n",
            "Epoch 93/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9270 - accuracy: 0.3200 - val_loss: 2.1429 - val_accuracy: 0.2885\n",
            "Epoch 94/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9237 - accuracy: 0.3196 - val_loss: 2.1645 - val_accuracy: 0.2878\n",
            "Epoch 95/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.9210 - accuracy: 0.3187 - val_loss: 2.1764 - val_accuracy: 0.2824\n",
            "Epoch 96/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.9205 - accuracy: 0.3170 - val_loss: 2.1550 - val_accuracy: 0.2835\n",
            "Epoch 97/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9185 - accuracy: 0.3225 - val_loss: 2.1698 - val_accuracy: 0.2885\n",
            "Epoch 98/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9194 - accuracy: 0.3208 - val_loss: 2.1609 - val_accuracy: 0.2871\n",
            "Epoch 99/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9172 - accuracy: 0.3199 - val_loss: 2.1592 - val_accuracy: 0.2900\n",
            "Epoch 100/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9162 - accuracy: 0.3201 - val_loss: 2.1680 - val_accuracy: 0.2760\n",
            "Epoch 101/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9145 - accuracy: 0.3205 - val_loss: 2.1736 - val_accuracy: 0.2796\n",
            "Epoch 102/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9128 - accuracy: 0.3214 - val_loss: 2.1721 - val_accuracy: 0.2824\n",
            "Epoch 103/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9154 - accuracy: 0.3217 - val_loss: 2.1698 - val_accuracy: 0.2853\n",
            "Epoch 104/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9107 - accuracy: 0.3217 - val_loss: 2.1821 - val_accuracy: 0.2803\n",
            "Epoch 105/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9117 - accuracy: 0.3207 - val_loss: 2.1744 - val_accuracy: 0.2799\n",
            "Epoch 106/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9095 - accuracy: 0.3251 - val_loss: 2.1696 - val_accuracy: 0.2839\n",
            "Epoch 107/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9038 - accuracy: 0.3236 - val_loss: 2.1778 - val_accuracy: 0.2896\n",
            "Epoch 108/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.9039 - accuracy: 0.3228 - val_loss: 2.1649 - val_accuracy: 0.2831\n",
            "Epoch 109/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.9028 - accuracy: 0.3265 - val_loss: 2.1888 - val_accuracy: 0.2914\n",
            "Epoch 110/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9028 - accuracy: 0.3239 - val_loss: 2.1702 - val_accuracy: 0.2781\n",
            "Epoch 111/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.9026 - accuracy: 0.3262 - val_loss: 2.2066 - val_accuracy: 0.2745\n",
            "Epoch 112/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8984 - accuracy: 0.3251 - val_loss: 2.1706 - val_accuracy: 0.2821\n",
            "Epoch 113/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.8990 - accuracy: 0.3260 - val_loss: 2.1621 - val_accuracy: 0.2835\n",
            "Epoch 114/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8981 - accuracy: 0.3272 - val_loss: 2.1915 - val_accuracy: 0.2846\n",
            "Epoch 115/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8984 - accuracy: 0.3238 - val_loss: 2.2046 - val_accuracy: 0.2821\n",
            "Epoch 116/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.8939 - accuracy: 0.3268 - val_loss: 2.2078 - val_accuracy: 0.2849\n",
            "Epoch 117/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8941 - accuracy: 0.3291 - val_loss: 2.1922 - val_accuracy: 0.2731\n",
            "Epoch 118/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8939 - accuracy: 0.3249 - val_loss: 2.1875 - val_accuracy: 0.2821\n",
            "Epoch 119/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8883 - accuracy: 0.3300 - val_loss: 2.2260 - val_accuracy: 0.2831\n",
            "Epoch 120/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8894 - accuracy: 0.3298 - val_loss: 2.1887 - val_accuracy: 0.2792\n",
            "Epoch 121/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8890 - accuracy: 0.3273 - val_loss: 2.1886 - val_accuracy: 0.2760\n",
            "Epoch 122/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8891 - accuracy: 0.3254 - val_loss: 2.1981 - val_accuracy: 0.2785\n",
            "Epoch 123/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8887 - accuracy: 0.3273 - val_loss: 2.2049 - val_accuracy: 0.2814\n",
            "Epoch 124/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8828 - accuracy: 0.3286 - val_loss: 2.2066 - val_accuracy: 0.2857\n",
            "Epoch 125/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8857 - accuracy: 0.3292 - val_loss: 2.2196 - val_accuracy: 0.2785\n",
            "Epoch 126/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.8845 - accuracy: 0.3292 - val_loss: 2.2185 - val_accuracy: 0.2849\n",
            "Epoch 127/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8825 - accuracy: 0.3327 - val_loss: 2.2159 - val_accuracy: 0.2763\n",
            "Epoch 128/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8798 - accuracy: 0.3294 - val_loss: 2.2231 - val_accuracy: 0.2824\n",
            "Epoch 129/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.8782 - accuracy: 0.3296 - val_loss: 2.2307 - val_accuracy: 0.2864\n",
            "Epoch 130/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8721 - accuracy: 0.3354 - val_loss: 2.2260 - val_accuracy: 0.2724\n",
            "Epoch 131/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8723 - accuracy: 0.3354 - val_loss: 2.2404 - val_accuracy: 0.2731\n",
            "Epoch 132/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8751 - accuracy: 0.3324 - val_loss: 2.2128 - val_accuracy: 0.2846\n",
            "Epoch 133/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8759 - accuracy: 0.3312 - val_loss: 2.2277 - val_accuracy: 0.2788\n",
            "Epoch 134/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8735 - accuracy: 0.3331 - val_loss: 2.2155 - val_accuracy: 0.2849\n",
            "Epoch 135/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.8685 - accuracy: 0.3358 - val_loss: 2.2429 - val_accuracy: 0.2821\n",
            "Epoch 136/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8691 - accuracy: 0.3357 - val_loss: 2.2342 - val_accuracy: 0.2745\n",
            "Epoch 137/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8691 - accuracy: 0.3353 - val_loss: 2.2478 - val_accuracy: 0.2706\n",
            "Epoch 138/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8646 - accuracy: 0.3355 - val_loss: 2.2429 - val_accuracy: 0.2731\n",
            "Epoch 139/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8651 - accuracy: 0.3326 - val_loss: 2.2432 - val_accuracy: 0.2763\n",
            "Epoch 140/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8623 - accuracy: 0.3368 - val_loss: 2.2432 - val_accuracy: 0.2742\n",
            "Epoch 141/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8657 - accuracy: 0.3331 - val_loss: 2.2132 - val_accuracy: 0.2788\n",
            "Epoch 142/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8589 - accuracy: 0.3358 - val_loss: 2.2339 - val_accuracy: 0.2738\n",
            "Epoch 143/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.8561 - accuracy: 0.3392 - val_loss: 2.2437 - val_accuracy: 0.2796\n",
            "Epoch 144/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8602 - accuracy: 0.3359 - val_loss: 2.2644 - val_accuracy: 0.2770\n",
            "Epoch 145/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8534 - accuracy: 0.3387 - val_loss: 2.2606 - val_accuracy: 0.2727\n",
            "Epoch 146/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8575 - accuracy: 0.3398 - val_loss: 2.2441 - val_accuracy: 0.2720\n",
            "Epoch 147/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8586 - accuracy: 0.3350 - val_loss: 2.2643 - val_accuracy: 0.2799\n",
            "Epoch 148/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8531 - accuracy: 0.3365 - val_loss: 2.2545 - val_accuracy: 0.2756\n",
            "Epoch 149/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8560 - accuracy: 0.3387 - val_loss: 2.2489 - val_accuracy: 0.2742\n",
            "Epoch 150/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8507 - accuracy: 0.3386 - val_loss: 2.2446 - val_accuracy: 0.2799\n",
            "Epoch 151/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8469 - accuracy: 0.3397 - val_loss: 2.2664 - val_accuracy: 0.2781\n",
            "Epoch 152/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.8448 - accuracy: 0.3436 - val_loss: 2.2689 - val_accuracy: 0.2767\n",
            "Epoch 153/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.8502 - accuracy: 0.3418 - val_loss: 2.2636 - val_accuracy: 0.2752\n",
            "Epoch 154/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8431 - accuracy: 0.3403 - val_loss: 2.2681 - val_accuracy: 0.2695\n",
            "Epoch 155/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8490 - accuracy: 0.3399 - val_loss: 2.2670 - val_accuracy: 0.2796\n",
            "Epoch 156/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8454 - accuracy: 0.3403 - val_loss: 2.2558 - val_accuracy: 0.2849\n",
            "Epoch 157/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8473 - accuracy: 0.3399 - val_loss: 2.2630 - val_accuracy: 0.2756\n",
            "Epoch 158/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8400 - accuracy: 0.3416 - val_loss: 2.3016 - val_accuracy: 0.2796\n",
            "Epoch 159/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8395 - accuracy: 0.3451 - val_loss: 2.2519 - val_accuracy: 0.2781\n",
            "Epoch 160/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8402 - accuracy: 0.3445 - val_loss: 2.2732 - val_accuracy: 0.2727\n",
            "Epoch 161/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8396 - accuracy: 0.3439 - val_loss: 2.2651 - val_accuracy: 0.2706\n",
            "Epoch 162/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8384 - accuracy: 0.3445 - val_loss: 2.2834 - val_accuracy: 0.2742\n",
            "Epoch 163/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8365 - accuracy: 0.3418 - val_loss: 2.2886 - val_accuracy: 0.2742\n",
            "Epoch 164/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8347 - accuracy: 0.3472 - val_loss: 2.2786 - val_accuracy: 0.2677\n",
            "Epoch 165/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8313 - accuracy: 0.3474 - val_loss: 2.2852 - val_accuracy: 0.2691\n",
            "Epoch 166/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8380 - accuracy: 0.3435 - val_loss: 2.2676 - val_accuracy: 0.2774\n",
            "Epoch 167/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8314 - accuracy: 0.3438 - val_loss: 2.3086 - val_accuracy: 0.2774\n",
            "Epoch 168/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8332 - accuracy: 0.3465 - val_loss: 2.2968 - val_accuracy: 0.2724\n",
            "Epoch 169/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8308 - accuracy: 0.3463 - val_loss: 2.3111 - val_accuracy: 0.2752\n",
            "Epoch 170/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8294 - accuracy: 0.3456 - val_loss: 2.3018 - val_accuracy: 0.2752\n",
            "Epoch 171/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8250 - accuracy: 0.3476 - val_loss: 2.2992 - val_accuracy: 0.2770\n",
            "Epoch 172/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8284 - accuracy: 0.3485 - val_loss: 2.2932 - val_accuracy: 0.2742\n",
            "Epoch 173/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8236 - accuracy: 0.3467 - val_loss: 2.2896 - val_accuracy: 0.2781\n",
            "Epoch 174/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8207 - accuracy: 0.3490 - val_loss: 2.3071 - val_accuracy: 0.2699\n",
            "Epoch 175/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8280 - accuracy: 0.3467 - val_loss: 2.2958 - val_accuracy: 0.2688\n",
            "Epoch 176/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8228 - accuracy: 0.3479 - val_loss: 2.2894 - val_accuracy: 0.2720\n",
            "Epoch 177/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8215 - accuracy: 0.3467 - val_loss: 2.3016 - val_accuracy: 0.2713\n",
            "Epoch 178/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8199 - accuracy: 0.3490 - val_loss: 2.3196 - val_accuracy: 0.2770\n",
            "Epoch 179/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8203 - accuracy: 0.3466 - val_loss: 2.3026 - val_accuracy: 0.2806\n",
            "Epoch 180/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8143 - accuracy: 0.3509 - val_loss: 2.3241 - val_accuracy: 0.2749\n",
            "Epoch 181/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8177 - accuracy: 0.3486 - val_loss: 2.3458 - val_accuracy: 0.2699\n",
            "Epoch 182/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8146 - accuracy: 0.3511 - val_loss: 2.3063 - val_accuracy: 0.2731\n",
            "Epoch 183/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8142 - accuracy: 0.3485 - val_loss: 2.3442 - val_accuracy: 0.2681\n",
            "Epoch 184/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8122 - accuracy: 0.3483 - val_loss: 2.3255 - val_accuracy: 0.2695\n",
            "Epoch 185/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8135 - accuracy: 0.3509 - val_loss: 2.3243 - val_accuracy: 0.2720\n",
            "Epoch 186/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8115 - accuracy: 0.3523 - val_loss: 2.3098 - val_accuracy: 0.2648\n",
            "Epoch 187/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8138 - accuracy: 0.3502 - val_loss: 2.3263 - val_accuracy: 0.2770\n",
            "Epoch 188/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8080 - accuracy: 0.3538 - val_loss: 2.3247 - val_accuracy: 0.2785\n",
            "Epoch 189/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8090 - accuracy: 0.3500 - val_loss: 2.3549 - val_accuracy: 0.2713\n",
            "Epoch 190/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8108 - accuracy: 0.3516 - val_loss: 2.3059 - val_accuracy: 0.2677\n",
            "Epoch 191/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8040 - accuracy: 0.3534 - val_loss: 2.3280 - val_accuracy: 0.2716\n",
            "Epoch 192/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8070 - accuracy: 0.3524 - val_loss: 2.3664 - val_accuracy: 0.2720\n",
            "Epoch 193/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8053 - accuracy: 0.3517 - val_loss: 2.3316 - val_accuracy: 0.2677\n",
            "Epoch 194/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8033 - accuracy: 0.3546 - val_loss: 2.3182 - val_accuracy: 0.2731\n",
            "Epoch 195/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7990 - accuracy: 0.3559 - val_loss: 2.3338 - val_accuracy: 0.2734\n",
            "Epoch 196/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.8000 - accuracy: 0.3530 - val_loss: 2.3474 - val_accuracy: 0.2742\n",
            "Epoch 197/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7993 - accuracy: 0.3525 - val_loss: 2.3548 - val_accuracy: 0.2720\n",
            "Epoch 198/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8011 - accuracy: 0.3554 - val_loss: 2.3052 - val_accuracy: 0.2760\n",
            "Epoch 199/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.8007 - accuracy: 0.3559 - val_loss: 2.3291 - val_accuracy: 0.2684\n",
            "Epoch 200/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7922 - accuracy: 0.3578 - val_loss: 2.3955 - val_accuracy: 0.2727\n",
            "Epoch 201/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7946 - accuracy: 0.3568 - val_loss: 2.3558 - val_accuracy: 0.2713\n",
            "Epoch 202/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7841 - accuracy: 0.3568 - val_loss: 2.3309 - val_accuracy: 0.2666\n",
            "Epoch 203/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7952 - accuracy: 0.3564 - val_loss: 2.3423 - val_accuracy: 0.2713\n",
            "Epoch 204/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7910 - accuracy: 0.3562 - val_loss: 2.3672 - val_accuracy: 0.2745\n",
            "Epoch 205/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7869 - accuracy: 0.3619 - val_loss: 2.3708 - val_accuracy: 0.2677\n",
            "Epoch 206/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7857 - accuracy: 0.3605 - val_loss: 2.3598 - val_accuracy: 0.2749\n",
            "Epoch 207/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7855 - accuracy: 0.3595 - val_loss: 2.3661 - val_accuracy: 0.2745\n",
            "Epoch 208/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7864 - accuracy: 0.3593 - val_loss: 2.3414 - val_accuracy: 0.2699\n",
            "Epoch 209/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7875 - accuracy: 0.3594 - val_loss: 2.3547 - val_accuracy: 0.2760\n",
            "Epoch 210/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7874 - accuracy: 0.3583 - val_loss: 2.3453 - val_accuracy: 0.2742\n",
            "Epoch 211/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7867 - accuracy: 0.3582 - val_loss: 2.3500 - val_accuracy: 0.2738\n",
            "Epoch 212/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7860 - accuracy: 0.3583 - val_loss: 2.3668 - val_accuracy: 0.2695\n",
            "Epoch 213/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7790 - accuracy: 0.3605 - val_loss: 2.3717 - val_accuracy: 0.2666\n",
            "Epoch 214/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7748 - accuracy: 0.3618 - val_loss: 2.3779 - val_accuracy: 0.2745\n",
            "Epoch 215/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7816 - accuracy: 0.3615 - val_loss: 2.3580 - val_accuracy: 0.2681\n",
            "Epoch 216/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7741 - accuracy: 0.3628 - val_loss: 2.3984 - val_accuracy: 0.2684\n",
            "Epoch 217/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7755 - accuracy: 0.3599 - val_loss: 2.3760 - val_accuracy: 0.2681\n",
            "Epoch 218/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7834 - accuracy: 0.3579 - val_loss: 2.3729 - val_accuracy: 0.2684\n",
            "Epoch 219/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7739 - accuracy: 0.3626 - val_loss: 2.3988 - val_accuracy: 0.2695\n",
            "Epoch 220/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7699 - accuracy: 0.3626 - val_loss: 2.3895 - val_accuracy: 0.2724\n",
            "Epoch 221/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7699 - accuracy: 0.3630 - val_loss: 2.4187 - val_accuracy: 0.2738\n",
            "Epoch 222/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7743 - accuracy: 0.3641 - val_loss: 2.4367 - val_accuracy: 0.2756\n",
            "Epoch 223/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7751 - accuracy: 0.3654 - val_loss: 2.3781 - val_accuracy: 0.2645\n",
            "Epoch 224/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7731 - accuracy: 0.3636 - val_loss: 2.4105 - val_accuracy: 0.2681\n",
            "Epoch 225/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.7710 - accuracy: 0.3657 - val_loss: 2.3764 - val_accuracy: 0.2727\n",
            "Epoch 226/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7710 - accuracy: 0.3640 - val_loss: 2.3988 - val_accuracy: 0.2670\n",
            "Epoch 227/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7731 - accuracy: 0.3632 - val_loss: 2.3987 - val_accuracy: 0.2648\n",
            "Epoch 228/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7595 - accuracy: 0.3700 - val_loss: 2.3860 - val_accuracy: 0.2709\n",
            "Epoch 229/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7644 - accuracy: 0.3668 - val_loss: 2.4173 - val_accuracy: 0.2684\n",
            "Epoch 230/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7657 - accuracy: 0.3657 - val_loss: 2.3654 - val_accuracy: 0.2716\n",
            "Epoch 231/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7708 - accuracy: 0.3664 - val_loss: 2.3987 - val_accuracy: 0.2677\n",
            "Epoch 232/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7648 - accuracy: 0.3677 - val_loss: 2.4070 - val_accuracy: 0.2681\n",
            "Epoch 233/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7668 - accuracy: 0.3664 - val_loss: 2.3979 - val_accuracy: 0.2724\n",
            "Epoch 234/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7629 - accuracy: 0.3648 - val_loss: 2.4061 - val_accuracy: 0.2731\n",
            "Epoch 235/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7630 - accuracy: 0.3637 - val_loss: 2.3838 - val_accuracy: 0.2734\n",
            "Epoch 236/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7618 - accuracy: 0.3670 - val_loss: 2.3863 - val_accuracy: 0.2702\n",
            "Epoch 237/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7522 - accuracy: 0.3712 - val_loss: 2.4037 - val_accuracy: 0.2706\n",
            "Epoch 238/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7583 - accuracy: 0.3664 - val_loss: 2.4127 - val_accuracy: 0.2727\n",
            "Epoch 239/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7596 - accuracy: 0.3671 - val_loss: 2.4061 - val_accuracy: 0.2634\n",
            "Epoch 240/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7558 - accuracy: 0.3709 - val_loss: 2.3980 - val_accuracy: 0.2670\n",
            "Epoch 241/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7548 - accuracy: 0.3697 - val_loss: 2.3830 - val_accuracy: 0.2681\n",
            "Epoch 242/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7574 - accuracy: 0.3715 - val_loss: 2.3903 - val_accuracy: 0.2691\n",
            "Epoch 243/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7586 - accuracy: 0.3690 - val_loss: 2.3834 - val_accuracy: 0.2637\n",
            "Epoch 244/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7439 - accuracy: 0.3711 - val_loss: 2.4700 - val_accuracy: 0.2634\n",
            "Epoch 245/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7565 - accuracy: 0.3703 - val_loss: 2.4081 - val_accuracy: 0.2655\n",
            "Epoch 246/1000\n",
            "1156/1156 [==============================] - 13s 11ms/step - loss: 1.7484 - accuracy: 0.3696 - val_loss: 2.4347 - val_accuracy: 0.2619\n",
            "Epoch 247/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7491 - accuracy: 0.3719 - val_loss: 2.4295 - val_accuracy: 0.2645\n",
            "Epoch 248/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7503 - accuracy: 0.3721 - val_loss: 2.4480 - val_accuracy: 0.2659\n",
            "Epoch 249/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7444 - accuracy: 0.3690 - val_loss: 2.4661 - val_accuracy: 0.2695\n",
            "Epoch 250/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7449 - accuracy: 0.3711 - val_loss: 2.4468 - val_accuracy: 0.2648\n",
            "Epoch 251/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7445 - accuracy: 0.3740 - val_loss: 2.4286 - val_accuracy: 0.2699\n",
            "Epoch 252/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7488 - accuracy: 0.3706 - val_loss: 2.4435 - val_accuracy: 0.2681\n",
            "Epoch 253/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.7426 - accuracy: 0.3712 - val_loss: 2.4369 - val_accuracy: 0.2652\n",
            "Epoch 254/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7407 - accuracy: 0.3774 - val_loss: 2.4084 - val_accuracy: 0.2749\n",
            "Epoch 255/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7412 - accuracy: 0.3740 - val_loss: 2.4800 - val_accuracy: 0.2695\n",
            "Epoch 256/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7339 - accuracy: 0.3766 - val_loss: 2.4737 - val_accuracy: 0.2641\n",
            "Epoch 257/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7367 - accuracy: 0.3755 - val_loss: 2.4860 - val_accuracy: 0.2684\n",
            "Epoch 258/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7461 - accuracy: 0.3747 - val_loss: 2.4218 - val_accuracy: 0.2695\n",
            "Epoch 259/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7367 - accuracy: 0.3746 - val_loss: 2.4465 - val_accuracy: 0.2645\n",
            "Epoch 260/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7422 - accuracy: 0.3751 - val_loss: 2.4682 - val_accuracy: 0.2688\n",
            "Epoch 261/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7342 - accuracy: 0.3784 - val_loss: 2.4550 - val_accuracy: 0.2695\n",
            "Epoch 262/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7424 - accuracy: 0.3737 - val_loss: 2.4492 - val_accuracy: 0.2566\n",
            "Epoch 263/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7391 - accuracy: 0.3736 - val_loss: 2.4591 - val_accuracy: 0.2594\n",
            "Epoch 264/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7351 - accuracy: 0.3758 - val_loss: 2.4826 - val_accuracy: 0.2670\n",
            "Epoch 265/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.7334 - accuracy: 0.3747 - val_loss: 2.4290 - val_accuracy: 0.2623\n",
            "Epoch 266/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7343 - accuracy: 0.3760 - val_loss: 2.4116 - val_accuracy: 0.2609\n",
            "Epoch 267/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7341 - accuracy: 0.3743 - val_loss: 2.4305 - val_accuracy: 0.2655\n",
            "Epoch 268/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7237 - accuracy: 0.3809 - val_loss: 2.4740 - val_accuracy: 0.2645\n",
            "Epoch 269/1000\n",
            "1156/1156 [==============================] - 13s 12ms/step - loss: 1.7185 - accuracy: 0.3802 - val_loss: 2.4805 - val_accuracy: 0.2645\n",
            "Epoch 270/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7282 - accuracy: 0.3796 - val_loss: 2.4604 - val_accuracy: 0.2756\n",
            "Epoch 271/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7290 - accuracy: 0.3766 - val_loss: 2.4821 - val_accuracy: 0.2652\n",
            "Epoch 272/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7261 - accuracy: 0.3797 - val_loss: 2.4605 - val_accuracy: 0.2691\n",
            "Epoch 273/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7240 - accuracy: 0.3796 - val_loss: 2.4380 - val_accuracy: 0.2630\n",
            "Epoch 274/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7210 - accuracy: 0.3815 - val_loss: 2.4677 - val_accuracy: 0.2670\n",
            "Epoch 275/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7331 - accuracy: 0.3759 - val_loss: 2.4464 - val_accuracy: 0.2670\n",
            "Epoch 276/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7191 - accuracy: 0.3813 - val_loss: 2.4652 - val_accuracy: 0.2623\n",
            "Epoch 277/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.7271 - accuracy: 0.3783 - val_loss: 2.4478 - val_accuracy: 0.2616\n",
            "Epoch 278/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7176 - accuracy: 0.3813 - val_loss: 2.4654 - val_accuracy: 0.2627\n",
            "Epoch 279/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7219 - accuracy: 0.3799 - val_loss: 2.4464 - val_accuracy: 0.2652\n",
            "Epoch 280/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7182 - accuracy: 0.3786 - val_loss: 2.4804 - val_accuracy: 0.2691\n",
            "Epoch 281/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7206 - accuracy: 0.3804 - val_loss: 2.4489 - val_accuracy: 0.2612\n",
            "Epoch 282/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7159 - accuracy: 0.3804 - val_loss: 2.4877 - val_accuracy: 0.2691\n",
            "Epoch 283/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7183 - accuracy: 0.3823 - val_loss: 2.4523 - val_accuracy: 0.2681\n",
            "Epoch 284/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7195 - accuracy: 0.3849 - val_loss: 2.4526 - val_accuracy: 0.2645\n",
            "Epoch 285/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7191 - accuracy: 0.3812 - val_loss: 2.4698 - val_accuracy: 0.2688\n",
            "Epoch 286/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7135 - accuracy: 0.3823 - val_loss: 2.4926 - val_accuracy: 0.2663\n",
            "Epoch 287/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7122 - accuracy: 0.3820 - val_loss: 2.4973 - val_accuracy: 0.2616\n",
            "Epoch 288/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7193 - accuracy: 0.3808 - val_loss: 2.4399 - val_accuracy: 0.2623\n",
            "Epoch 289/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.7197 - accuracy: 0.3829 - val_loss: 2.4604 - val_accuracy: 0.2652\n",
            "Epoch 290/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7078 - accuracy: 0.3855 - val_loss: 2.5014 - val_accuracy: 0.2627\n",
            "Epoch 291/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7140 - accuracy: 0.3847 - val_loss: 2.5077 - val_accuracy: 0.2616\n",
            "Epoch 292/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7103 - accuracy: 0.3822 - val_loss: 2.4679 - val_accuracy: 0.2670\n",
            "Epoch 293/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7180 - accuracy: 0.3820 - val_loss: 2.4751 - val_accuracy: 0.2609\n",
            "Epoch 294/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7044 - accuracy: 0.3851 - val_loss: 2.5071 - val_accuracy: 0.2659\n",
            "Epoch 295/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7008 - accuracy: 0.3862 - val_loss: 2.4791 - val_accuracy: 0.2652\n",
            "Epoch 296/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7109 - accuracy: 0.3825 - val_loss: 2.4622 - val_accuracy: 0.2616\n",
            "Epoch 297/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7029 - accuracy: 0.3836 - val_loss: 2.5095 - val_accuracy: 0.2627\n",
            "Epoch 298/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7069 - accuracy: 0.3838 - val_loss: 2.4753 - val_accuracy: 0.2720\n",
            "Epoch 299/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7054 - accuracy: 0.3855 - val_loss: 2.4627 - val_accuracy: 0.2673\n",
            "Epoch 300/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7051 - accuracy: 0.3831 - val_loss: 2.4543 - val_accuracy: 0.2573\n",
            "Epoch 301/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6937 - accuracy: 0.3889 - val_loss: 2.4733 - val_accuracy: 0.2645\n",
            "Epoch 302/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7017 - accuracy: 0.3859 - val_loss: 2.5481 - val_accuracy: 0.2641\n",
            "Epoch 303/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7025 - accuracy: 0.3871 - val_loss: 2.5064 - val_accuracy: 0.2670\n",
            "Epoch 304/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7047 - accuracy: 0.3848 - val_loss: 2.5069 - val_accuracy: 0.2587\n",
            "Epoch 305/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6986 - accuracy: 0.3877 - val_loss: 2.4890 - val_accuracy: 0.2612\n",
            "Epoch 306/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6938 - accuracy: 0.3864 - val_loss: 2.5022 - val_accuracy: 0.2627\n",
            "Epoch 307/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6999 - accuracy: 0.3888 - val_loss: 2.5254 - val_accuracy: 0.2605\n",
            "Epoch 308/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6984 - accuracy: 0.3858 - val_loss: 2.5068 - val_accuracy: 0.2691\n",
            "Epoch 309/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6932 - accuracy: 0.3902 - val_loss: 2.4928 - val_accuracy: 0.2634\n",
            "Epoch 310/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6998 - accuracy: 0.3884 - val_loss: 2.5245 - val_accuracy: 0.2645\n",
            "Epoch 311/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6953 - accuracy: 0.3879 - val_loss: 2.5564 - val_accuracy: 0.2487\n",
            "Epoch 312/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6913 - accuracy: 0.3901 - val_loss: 2.5188 - val_accuracy: 0.2637\n",
            "Epoch 313/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.7026 - accuracy: 0.3878 - val_loss: 2.5294 - val_accuracy: 0.2587\n",
            "Epoch 314/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6946 - accuracy: 0.3869 - val_loss: 2.5320 - val_accuracy: 0.2623\n",
            "Epoch 315/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6929 - accuracy: 0.3894 - val_loss: 2.5574 - val_accuracy: 0.2598\n",
            "Epoch 316/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6897 - accuracy: 0.3888 - val_loss: 2.4970 - val_accuracy: 0.2580\n",
            "Epoch 317/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6900 - accuracy: 0.3940 - val_loss: 2.4595 - val_accuracy: 0.2645\n",
            "Epoch 318/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6826 - accuracy: 0.3922 - val_loss: 2.5337 - val_accuracy: 0.2616\n",
            "Epoch 319/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6908 - accuracy: 0.3932 - val_loss: 2.4860 - val_accuracy: 0.2659\n",
            "Epoch 320/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6917 - accuracy: 0.3906 - val_loss: 2.4848 - val_accuracy: 0.2677\n",
            "Epoch 321/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6830 - accuracy: 0.3939 - val_loss: 2.5626 - val_accuracy: 0.2670\n",
            "Epoch 322/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6886 - accuracy: 0.3904 - val_loss: 2.5142 - val_accuracy: 0.2612\n",
            "Epoch 323/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6809 - accuracy: 0.3925 - val_loss: 2.5101 - val_accuracy: 0.2569\n",
            "Epoch 324/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6809 - accuracy: 0.3937 - val_loss: 2.5404 - val_accuracy: 0.2652\n",
            "Epoch 325/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6862 - accuracy: 0.3945 - val_loss: 2.5547 - val_accuracy: 0.2738\n",
            "Epoch 326/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6797 - accuracy: 0.3917 - val_loss: 2.5756 - val_accuracy: 0.2623\n",
            "Epoch 327/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6769 - accuracy: 0.3943 - val_loss: 2.5388 - val_accuracy: 0.2591\n",
            "Epoch 328/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6824 - accuracy: 0.3925 - val_loss: 2.5991 - val_accuracy: 0.2681\n",
            "Epoch 329/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6820 - accuracy: 0.3930 - val_loss: 2.5021 - val_accuracy: 0.2655\n",
            "Epoch 330/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6753 - accuracy: 0.3961 - val_loss: 2.5458 - val_accuracy: 0.2630\n",
            "Epoch 331/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6844 - accuracy: 0.3953 - val_loss: 2.5732 - val_accuracy: 0.2648\n",
            "Epoch 332/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6812 - accuracy: 0.3911 - val_loss: 2.5093 - val_accuracy: 0.2605\n",
            "Epoch 333/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6789 - accuracy: 0.3943 - val_loss: 2.5148 - val_accuracy: 0.2659\n",
            "Epoch 334/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6765 - accuracy: 0.3962 - val_loss: 2.5410 - val_accuracy: 0.2634\n",
            "Epoch 335/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6736 - accuracy: 0.3947 - val_loss: 2.5736 - val_accuracy: 0.2544\n",
            "Epoch 336/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6721 - accuracy: 0.3955 - val_loss: 2.5485 - val_accuracy: 0.2670\n",
            "Epoch 337/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6791 - accuracy: 0.3936 - val_loss: 2.5224 - val_accuracy: 0.2573\n",
            "Epoch 338/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6719 - accuracy: 0.3949 - val_loss: 2.6329 - val_accuracy: 0.2605\n",
            "Epoch 339/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6751 - accuracy: 0.3929 - val_loss: 2.5493 - val_accuracy: 0.2630\n",
            "Epoch 340/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6721 - accuracy: 0.3972 - val_loss: 2.5349 - val_accuracy: 0.2569\n",
            "Epoch 341/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6692 - accuracy: 0.3987 - val_loss: 2.5717 - val_accuracy: 0.2555\n",
            "Epoch 342/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6714 - accuracy: 0.3970 - val_loss: 2.5116 - val_accuracy: 0.2562\n",
            "Epoch 343/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6740 - accuracy: 0.3980 - val_loss: 2.5521 - val_accuracy: 0.2598\n",
            "Epoch 344/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6704 - accuracy: 0.3963 - val_loss: 2.5165 - val_accuracy: 0.2627\n",
            "Epoch 345/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6662 - accuracy: 0.3980 - val_loss: 2.5868 - val_accuracy: 0.2573\n",
            "Epoch 346/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6721 - accuracy: 0.3949 - val_loss: 2.5548 - val_accuracy: 0.2691\n",
            "Epoch 347/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6709 - accuracy: 0.3971 - val_loss: 2.5730 - val_accuracy: 0.2551\n",
            "Epoch 348/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6713 - accuracy: 0.3980 - val_loss: 2.5425 - val_accuracy: 0.2562\n",
            "Epoch 349/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6653 - accuracy: 0.3971 - val_loss: 2.5452 - val_accuracy: 0.2598\n",
            "Epoch 350/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6684 - accuracy: 0.3981 - val_loss: 2.5251 - val_accuracy: 0.2609\n",
            "Epoch 351/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6619 - accuracy: 0.4007 - val_loss: 2.5864 - val_accuracy: 0.2634\n",
            "Epoch 352/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6626 - accuracy: 0.3989 - val_loss: 2.5354 - val_accuracy: 0.2576\n",
            "Epoch 353/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6647 - accuracy: 0.3990 - val_loss: 2.5726 - val_accuracy: 0.2616\n",
            "Epoch 354/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6643 - accuracy: 0.4011 - val_loss: 2.5621 - val_accuracy: 0.2587\n",
            "Epoch 355/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6772 - accuracy: 0.3953 - val_loss: 2.5468 - val_accuracy: 0.2609\n",
            "Epoch 356/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6724 - accuracy: 0.3993 - val_loss: 2.5397 - val_accuracy: 0.2623\n",
            "Epoch 357/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6617 - accuracy: 0.3991 - val_loss: 2.5830 - val_accuracy: 0.2594\n",
            "Epoch 358/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6588 - accuracy: 0.4003 - val_loss: 2.5497 - val_accuracy: 0.2673\n",
            "Epoch 359/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6566 - accuracy: 0.3996 - val_loss: 2.5898 - val_accuracy: 0.2587\n",
            "Epoch 360/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6663 - accuracy: 0.3986 - val_loss: 2.5803 - val_accuracy: 0.2627\n",
            "Epoch 361/1000\n",
            "1156/1156 [==============================] - 14s 13ms/step - loss: 1.6571 - accuracy: 0.4037 - val_loss: 2.6306 - val_accuracy: 0.2558\n",
            "Epoch 362/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6596 - accuracy: 0.4022 - val_loss: 2.5834 - val_accuracy: 0.2540\n",
            "Epoch 363/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6543 - accuracy: 0.4030 - val_loss: 2.5792 - val_accuracy: 0.2609\n",
            "Epoch 364/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6610 - accuracy: 0.4021 - val_loss: 2.5904 - val_accuracy: 0.2652\n",
            "Epoch 365/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6532 - accuracy: 0.4026 - val_loss: 2.5795 - val_accuracy: 0.2566\n",
            "Epoch 366/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6585 - accuracy: 0.4006 - val_loss: 2.5753 - val_accuracy: 0.2562\n",
            "Epoch 367/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6606 - accuracy: 0.4006 - val_loss: 2.6237 - val_accuracy: 0.2573\n",
            "Epoch 368/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6540 - accuracy: 0.4033 - val_loss: 2.5513 - val_accuracy: 0.2641\n",
            "Epoch 369/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6523 - accuracy: 0.4053 - val_loss: 2.5934 - val_accuracy: 0.2655\n",
            "Epoch 370/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6603 - accuracy: 0.4016 - val_loss: 2.5547 - val_accuracy: 0.2609\n",
            "Epoch 371/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6502 - accuracy: 0.4015 - val_loss: 2.5240 - val_accuracy: 0.2627\n",
            "Epoch 372/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6476 - accuracy: 0.4052 - val_loss: 2.5746 - val_accuracy: 0.2612\n",
            "Epoch 373/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6570 - accuracy: 0.4008 - val_loss: 2.4967 - val_accuracy: 0.2616\n",
            "Epoch 374/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6491 - accuracy: 0.4043 - val_loss: 2.6145 - val_accuracy: 0.2562\n",
            "Epoch 375/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6441 - accuracy: 0.4068 - val_loss: 2.6020 - val_accuracy: 0.2573\n",
            "Epoch 376/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6456 - accuracy: 0.4022 - val_loss: 2.5978 - val_accuracy: 0.2576\n",
            "Epoch 377/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6468 - accuracy: 0.4056 - val_loss: 2.6318 - val_accuracy: 0.2566\n",
            "Epoch 378/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6492 - accuracy: 0.4048 - val_loss: 2.5847 - val_accuracy: 0.2598\n",
            "Epoch 379/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6399 - accuracy: 0.4080 - val_loss: 2.6313 - val_accuracy: 0.2555\n",
            "Epoch 380/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6500 - accuracy: 0.4082 - val_loss: 2.6465 - val_accuracy: 0.2562\n",
            "Epoch 381/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6439 - accuracy: 0.4061 - val_loss: 2.6281 - val_accuracy: 0.2587\n",
            "Epoch 382/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6435 - accuracy: 0.4077 - val_loss: 2.6034 - val_accuracy: 0.2569\n",
            "Epoch 383/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6428 - accuracy: 0.4058 - val_loss: 2.6275 - val_accuracy: 0.2515\n",
            "Epoch 384/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6319 - accuracy: 0.4087 - val_loss: 2.6497 - val_accuracy: 0.2548\n",
            "Epoch 385/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6455 - accuracy: 0.4056 - val_loss: 2.6274 - val_accuracy: 0.2537\n",
            "Epoch 386/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6423 - accuracy: 0.4044 - val_loss: 2.6174 - val_accuracy: 0.2555\n",
            "Epoch 387/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6450 - accuracy: 0.4058 - val_loss: 2.6580 - val_accuracy: 0.2526\n",
            "Epoch 388/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6449 - accuracy: 0.4066 - val_loss: 2.6630 - val_accuracy: 0.2576\n",
            "Epoch 389/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6384 - accuracy: 0.4081 - val_loss: 2.6781 - val_accuracy: 0.2519\n",
            "Epoch 390/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6362 - accuracy: 0.4072 - val_loss: 2.6793 - val_accuracy: 0.2504\n",
            "Epoch 391/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6378 - accuracy: 0.4073 - val_loss: 2.6361 - val_accuracy: 0.2598\n",
            "Epoch 392/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6367 - accuracy: 0.4083 - val_loss: 2.6583 - val_accuracy: 0.2594\n",
            "Epoch 393/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6308 - accuracy: 0.4080 - val_loss: 2.5941 - val_accuracy: 0.2558\n",
            "Epoch 394/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6412 - accuracy: 0.4057 - val_loss: 2.6328 - val_accuracy: 0.2587\n",
            "Epoch 395/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6391 - accuracy: 0.4067 - val_loss: 2.6167 - val_accuracy: 0.2558\n",
            "Epoch 396/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6386 - accuracy: 0.4062 - val_loss: 2.6628 - val_accuracy: 0.2537\n",
            "Epoch 397/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6320 - accuracy: 0.4095 - val_loss: 2.6026 - val_accuracy: 0.2476\n",
            "Epoch 398/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6346 - accuracy: 0.4051 - val_loss: 2.6186 - val_accuracy: 0.2551\n",
            "Epoch 399/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6434 - accuracy: 0.4067 - val_loss: 2.5921 - val_accuracy: 0.2558\n",
            "Epoch 400/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6311 - accuracy: 0.4099 - val_loss: 2.6299 - val_accuracy: 0.2515\n",
            "Epoch 401/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6387 - accuracy: 0.4077 - val_loss: 2.6323 - val_accuracy: 0.2537\n",
            "Epoch 402/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6327 - accuracy: 0.4081 - val_loss: 2.6100 - val_accuracy: 0.2602\n",
            "Epoch 403/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6308 - accuracy: 0.4113 - val_loss: 2.6122 - val_accuracy: 0.2504\n",
            "Epoch 404/1000\n",
            "1156/1156 [==============================] - 14s 13ms/step - loss: 1.6322 - accuracy: 0.4105 - val_loss: 2.6652 - val_accuracy: 0.2619\n",
            "Epoch 405/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6259 - accuracy: 0.4105 - val_loss: 2.6968 - val_accuracy: 0.2537\n",
            "Epoch 406/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6258 - accuracy: 0.4118 - val_loss: 2.6734 - val_accuracy: 0.2522\n",
            "Epoch 407/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6328 - accuracy: 0.4086 - val_loss: 2.6560 - val_accuracy: 0.2544\n",
            "Epoch 408/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6300 - accuracy: 0.4078 - val_loss: 2.6692 - val_accuracy: 0.2584\n",
            "Epoch 409/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6237 - accuracy: 0.4102 - val_loss: 2.6382 - val_accuracy: 0.2530\n",
            "Epoch 410/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6281 - accuracy: 0.4126 - val_loss: 2.6978 - val_accuracy: 0.2497\n",
            "Epoch 411/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6242 - accuracy: 0.4109 - val_loss: 2.7038 - val_accuracy: 0.2519\n",
            "Epoch 412/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6250 - accuracy: 0.4109 - val_loss: 2.7033 - val_accuracy: 0.2562\n",
            "Epoch 413/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6293 - accuracy: 0.4109 - val_loss: 2.6650 - val_accuracy: 0.2548\n",
            "Epoch 414/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6272 - accuracy: 0.4106 - val_loss: 2.6803 - val_accuracy: 0.2630\n",
            "Epoch 415/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6194 - accuracy: 0.4143 - val_loss: 2.7187 - val_accuracy: 0.2522\n",
            "Epoch 416/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6344 - accuracy: 0.4090 - val_loss: 2.6560 - val_accuracy: 0.2555\n",
            "Epoch 417/1000\n",
            "1156/1156 [==============================] - 14s 13ms/step - loss: 1.6234 - accuracy: 0.4121 - val_loss: 2.6665 - val_accuracy: 0.2537\n",
            "Epoch 418/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6230 - accuracy: 0.4137 - val_loss: 2.6760 - val_accuracy: 0.2580\n",
            "Epoch 419/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6294 - accuracy: 0.4108 - val_loss: 2.6312 - val_accuracy: 0.2598\n",
            "Epoch 420/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6176 - accuracy: 0.4134 - val_loss: 2.6846 - val_accuracy: 0.2544\n",
            "Epoch 421/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6214 - accuracy: 0.4127 - val_loss: 2.6718 - val_accuracy: 0.2522\n",
            "Epoch 422/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6313 - accuracy: 0.4098 - val_loss: 2.6716 - val_accuracy: 0.2487\n",
            "Epoch 423/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6194 - accuracy: 0.4136 - val_loss: 2.6801 - val_accuracy: 0.2566\n",
            "Epoch 424/1000\n",
            "1156/1156 [==============================] - 14s 12ms/step - loss: 1.6211 - accuracy: 0.4139 - val_loss: 2.7005 - val_accuracy: 0.2566\n",
            "Epoch 425/1000\n",
            "1156/1156 [==============================] - 15s 13ms/step - loss: 1.6211 - accuracy: 0.4125 - val_loss: 2.6659 - val_accuracy: 0.2530\n",
            "Epoch 426/1000\n",
            "  97/1156 [=>............................] - ETA: 12s - loss: 1.6188 - accuracy: 0.4175"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-160-f7b41c3be4b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_best\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \"\"\"\n\u001b[1;32m   1158\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRuvGjLNCO8A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8lgyXmqhxTC3wG2wgJ9oE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}